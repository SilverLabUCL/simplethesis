@article{Cannon2007,
   author = {Cannon, Robert and Gewaltig, Marc-Oliver and Gleeson, Padraig and Bhalla, Upinder and Cornelis, Hugo and Hines, Michael and Howell, Fredrick and Muller, Eilif and Stiles, Joel and Wils, Stefan and De Schutter, Erik},
   title = {Interoperability of Neuroscience Modeling Software: Current Status and Future Directions},
   journal = {Neuroinformatics},
   volume = {5},
   number = {2},
   pages = {127-138},
   abstract = {Abstract&nbsp;&nbsp;Neuroscience increasingly uses computational models to assist in the exploration and interpretation of complex phenomena. As a result, considerable effort is invested in the development of software tools and technologies for numerical simulations and for the creation and publication of models. The diversity of related tools leads to the duplication of effort and hinders model reuse. Development practices and technologies that support interoperability between software systems therefore play an important role in making the modeling process more efficient and in ensuring that published models can be reliably and easily reused. Various forms of interoperability are possible including the development of portable model description standards, the adoption of common simulation languages or the use of standardized middleware. Each of these approaches finds applications within the broad range of current modeling activity. However more effort is required in many areas to enable new scientific questions to be addressed. Here we present the conclusions of the "Neuro-IT Interoperability of Simulators" workshop, held at the 11th computational neuroscience meeting in Edinburgh (July 19-20 2006; http://www.cnsorg.org). We assess the current state of interoperability of neural simulation software and explore the future directions that will enable the field to advance.},
   year = {2007}
}

@article{Gabbiani1994,
author = {Gabbiani, F. and Midtgaard, J. and Knopfel, T.}, 
title = {Synaptic integration in a model of cerebellar granule cells}, 
volume = {72}, 
number = {2}, 
pages = {999-1009}, 
year = {1994}, 
abstract ={1. We have developed a compartmental model of a turtle cerebellar granule cell consisting of 13 compartmentds that represent the soma and 4 dendrites. We used this model to investigate the synaptic integration of mossy fiber inputs in granule cells. 2. The somatic compartment contained six active ionic conductances: a sodium conductance with fast activation and inactivation kinetics, gNa; a high-voltage-activated calcium conductance, gCa(HVA); a delayed potassium conductance, gK(DR); a transient potassium conductance, gK(A); a slowly relaxing mixed Na+/K+ conductance activating at hyperpolarized membrane potentials, gH, and a calcium- and voltage-dependent potassium conductance, gK(Ca). The kinetics of these conductances was derived from electrophysiological studies in a variety of preparations, including turtle and rat granule cells. 3. In the soma, dynamics of intracellular free Ca2+ was modeled by incorporation of a Na+/Ca2+ exchanger, radial diffusion, and binding sites for Ca2+. 4. The model of the turtle granule cell exhibited depolarization-induced action potential firing with properties closely resembling those seen with intracellular recordings in turtle granule cells in vitro. 5. In the most distal compartments of the dendrites, mossy fiber activity induced synaptic currents mediated by alpha-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid (AMPA)- and N-methyl-D-aspartate (NMDA)-type of glutamate receptors. The strength of synaptic inputs chosen was such that the synaptic potential induced by synchronous activation of two mossy fiber synapses reached threshold for induction of a single action potential. 6. The slow time course of the NMDA synaptic current together with the slow relaxation kinetics of gH significantly affected the temporal summation of excitatory synaptic potentials. A priming action potential evoked by mossy fiber stimulation increased the maximal time interval between two synaptic potentials capable to reach again threshold for a subsequent action potential. This time interval then decreased in parallel with the decay of the NMDA synaptic current, reached a minimum after 200 ms, and slowly recovered with reactivation of gH. 7. Repetitive, steady activation of synaptic conductances by a single mossy fiber at different frequencies induced action potential firing with a sharp threshold at 12 Hz. Activity of a single or of several mossy fibers induced firing of the granule cell at a frequency close to that induced when the average synaptic current was directly injected into the cell. The mossy fiber activity-granule cell firing frequency curve was close to linear with a slope of about one-half for input frequencies < or = 400 Hz.(ABSTRACT TRUNCATED AT 400 WORDS)}, 
journal = {Journal of Neurophysiology} 
}


@article{Crook2007,
   author = {Crook, S. and Gleeson, P. and Howell, F. and Svitak, J. and Silver, R. A.},
   title = {Morph{ML}: {L}evel 1 of the {N}euro{ML} standards for neuronal morphology data and model specification},
   journal = {Neuroinformatics},
   volume = {5},
   number = {2},
   pages = {96-104},
   abstract = {Quantitative neuroanatomical data are important for the study of many areas of neuroscience, and the complexity of problems associated with neuronal structure requires that research from multiple groups across many disciplines be combined. However, existing neuron-tracing systems, simulation environments, and tools for the visualization and analysis of neuronal morphology data use a variety of data formats, making it difficult to exchange data in a readily usable way. The NeuroML project was initiated to address these issues, and here we describe an extensible markup language standard, MorphML, which defines a common data format for neuronal morphology data and associated metadata to facilitate data and model exchange, database creation, model publication, and data archiving. We describe the elements of the standard in detail and outline the mappings between this format and those used by a number of popular applications for reconstruction, simulation, and visualization of neuronal morphology.},
   keywords = {Computer Simulation
Image Processing, Computer-Assisted
*Models, Neurological
Neuroanatomy/*methods/*standards
Neurons/*ultrastructure
Reference Standards
Software},
   year = {2007}
}

@article{Kopell2005,
author = {Kopell, Nancy}, 
title = {Does it Have to be This Complicated? {F}ocus on ``{S}ingle-Column Thalamocortical Network Model Exhibiting Gamma Oscillations, Spindles, and Epileptogenic Bursts''}, 
volume = {93}, 
number = {4}, 
pages = {1829-1830}, 
year = {2005}, 
doi = {10.1152/jn.01147.2004}, 
journal = {Journal of Neurophysiology} 
}

@article{Gardner2001,
   author = {Gardner, D. and Knuth, K. H. and Abato, M. and Erde, S. M. and White, T. and DeBellis, R. and Gardner, E. P.},
   title = {Common data model for neuroscience data and data model exchange},
   journal = {Journal of the American Medical Informatics Association},
   volume = {8},
   number = {1},
   pages = {17-33},
   abstract = {OBJECTIVE: Generalizing the data models underlying two prototype neurophysiology databases, the authors describe and propose the Common Data Model (CDM) as a framework for federating a broad spectrum of disparate neuroscience information resources. DESIGN: Each component of the CDM derives from one of five superclasses-data, site, method, model, and reference-or from relations defined between them. A hierarchic attribute-value scheme for metadata enables interoperability with variable tree depth to serve specific intra- or broad inter-domain queries. To mediate data exchange between disparate systems, the authors propose a set of XML-derived schema for describing not only data sets but data models. These include biophysical description markup language (BDML), which mediates interoperability between data resources by providing a meta-description for the CDM. RESULTS: The set of superclasses potentially spans data needs of contemporary neuroscience. Data elements abstracted from neurophysiology time series and histogram data represent data sets that differ in dimension and concordance. Site elements transcend neurons to describe subcellular compartments, circuits, regions, or slices; non-neuroanatomic sites include sequences to patients. Methods and models are highly domain-dependent. CONCLUSIONS: True federation of data resources requires explicit public description, in a metalanguage, of the contents, query methods, data formats, and data models of each data resource. Any data model that can be derived from the defined superclasses is potentially conformant and interoperability can be enabled by recognition of BDML-described compatibilities. Such metadescriptions can buffer technologic changes.},
   keywords = {Animals
Brain/physiology
Computer Communication Networks/standards
Databases, Factual/*standards
Information Storage and Retrieval/standards
Neurons
Neurophysiology
Neurosciences/*organization & administration
Programming Languages
*Systems Integration
Vocabulary, Controlled},
   year = {2001}
}

@article{GleesonEtAl2007,
   author = {Gleeson, P. and Steuber, V. and Silver, R. A.},
   title = {neuro{C}onstruct: a tool for modeling networks of neurons in 3{D} space},
   journal = {Neuron},
   volume = {54},
   number = {2},
   pages = {219-35},
   abstract = {Conductance-based neuronal network models can help us understand how synaptic and cellular mechanisms underlie brain function. However, these complex models are difficult to develop and are inaccessible to most neuroscientists. Moreover, even the most biologically realistic network models disregard many 3D anatomical features of the brain. Here, we describe a new software application, neuroConstruct, that facilitates the creation, visualization, and analysis of networks of multicompartmental neurons in 3D space. A graphical user interface allows model generation and modification without programming. Models within neuroConstruct are based on new simulator-independent NeuroML standards, allowing automatic generation of code for NEURON or GENESIS simulators. neuroConstruct was tested by reproducing published models and its simulator independence verified by comparing the same model on two simulators. We show how more anatomically realistic network models can be created and their properties compared with experimental measurements by extending a published 1D cerebellar granule cell layer model to 3D.},
   keywords = {Algorithms
Cerebellar Cortex/cytology/physiology
Computer Simulation
Dentate Gyrus/physiology
Humans
Models, Neurological
Neural Conduction/physiology
*Neural Networks (Computer)
Neurons/*physiology/ultrastructure},
   year = {2007}
}

@article{Goddard2001,
   author = {Goddard, N. H. and Hucka, M. and Howell, F. and Cornelis, H. and Shankar, K. and Beeman, D.},
   title = {Towards {N}euro{ML}: model description methods for collaborative modelling in neuroscience},
   journal = {Philos Trans R Soc Lond B Biol Sci},
   volume = {356},
   number = {1412},
   pages = {1209-28},
   abstract = {Biological nervous systems and the mechanisms underlying their operation exhibit astonishing complexity. Computational models of these systems have been correspondingly complex. As these models become ever more sophisticated, they become increasingly difficult to define, comprehend, manage and communicate. Consequently, for scientific understanding of biological nervous systems to progress, it is crucial for modellers to have software tools that support discussion, development and exchange of computational models. We describe methodologies that focus on these tasks, improving the ability of neuroscientists to engage in the modelling process. We report our findings on the requirements for these tools and discuss the use of declarative forms of model description--equivalent to object-oriented classes and database schema--which we call templates. We introduce NeuroML, a mark-up language for the neurosciences which is defined syntactically using templates, and its specific component intended as a common format for communication between modelling-related tools. Finally, we propose a template hierarchy for this modelling component of NeuroML, sufficient for describing models ranging in structural levels from neuron cell membranes to neural networks. These templates support both a framework for user-level interaction with models, and a high-performance framework for efficient simulation of the models.},
   keywords = {Animals
*Computer Simulation
Cooperative Behavior
Humans
*Models, Neurological
Neurosciences/*methods
Research Support, Non-U.S. Gov't
Research Support, U.S. Gov't, P.H.S.
Software},
   year = {2001}
}

@article{Neosim,
   author = {Howell, F. and Cannon, R. and Goddard, N. and Bringmann, H. and Rogister, P. and Cornelis, H.},
   title = {Linking computational neuroscience simulation tools--a pragmatic approach to component-based development},
   journal = {Neurocomputing},
   volume = {52-54},
   pages = {289-294},
   keywords = {Neural simulation tools
Modelling
Simulation
Software},
   year = {2003}
}

@article{Qi2004,
   author = {Qi, Weihong and Crook, Sharon},
   title = {Tools for neuroinformatic data exchange: an {XML} application for neuronal morphology data},
   journal = {Neurocomputing},
   volume = {58-60},
   pages = {1091-1095},
   keywords = {Neuronal morphology data
XML application
Digitized neurons},
   year = {2004}
}

@article{Hines2004,
   author = {Hines, M. L. and Morse, T. and Migliore, M. and Carnevale, N. T. and Shepherd, G. M.},
   title = {Model{DB}: A Database to Support Computational Neuroscience},
   journal = {Journal of Computational Neuroscience},
   volume = {17},
   number = {1},
   pages = {7-11},
   abstract = {Wider dissemination and testing of computational models are crucial to the field of computational neuroscience. Databases are being developed to meet this need. ModelDB is a web-accessible database for convenient entry, retrieval, and running of published models on different platforms. This article provides a guide to entering a new model into ModelDB.},
   keywords = {Animals
*Computational Biology
Computer Communication Networks
*Databases, Factual
Humans
*Neurosciences
Research Support, U.S. Gov't, P.H.S.
Systems Integration},
   year = {2004}
}


@book{NEURONBook,
   author = {Carnevale, Nicholas T. and Hines, Michael L.},
   title = {The NEURON Book},
   publisher = {Cambridge University Press},
   year = {2006}
}


@book{GENESISBook,
   author = {Bower, J.M. and Beeman, D.},
   title = {The Book of GENESIS: Exploring Realistic Neural Models with the GEneral NEural SImulation System},
   publisher = {Springer, New York},
   year = {1997}
}

@article{DeSchutter2008,
   author = {De Schutter, E.},
   title = {Why are computational neuroscience and systems biology so separate?},
   journal = {PLoS Computational Biology},
   volume = {4},
   number = {5},
   pages = {e1000078},
   abstract = {Despite similar computational approaches, there is surprisingly little interaction between the computational neuroscience and the systems biology research communities. In this review I reconstruct the history of the two disciplines and show that this may explain why they grew up apart. The separation is a pity, as both fields can learn quite a bit from each other. Several examples are given, covering sociological, software technical, and methodological aspects. Systems biology is a better organized community which is very effective at sharing resources, while computational neuroscience has more experience in multiscale modeling and the analysis of information processing by biological systems. Finally, I speculate about how the relationship between the two fields may evolve in the near future.},
   keywords = {Computer Simulation
*Models, Neurological
Neurosciences/*trends
Systems Biology/*trends},
   year = {2008}
}

@article{BretteEtAl2007,
   author = {Brette, R. and Rudolph, M. and Carnevale, T. and Hines, M. and Beeman, D. and Bower, J. M. and Diesmann, M. and Morrison, A. and Goodman, P. H. and Harris, F. C., Jr. and Zirpe, M. and Natschlager, T. and Pecevski, D. and Ermentrout, B. and Djurfeldt, M. and Lansner, A. and Rochel, O. and Vieville, T. and Muller, E. and Davison, A. P. and El Boustani, S. and Destexhe, A.},
   title = {Simulation of networks of spiking neurons: a review of tools and strategies},
   journal = {Journal of Computational Neuroscience},
   volume = {23},
   number = {3},
   pages = {349-98},
   abstract = {We review different aspects of the simulation of spiking neural networks. We start by reviewing the different types of simulation strategies and algorithms that are currently implemented. We next review the precision of those simulation strategies, in particular in cases where plasticity depends on the exact timing of the spikes. We overview different simulators and simulation environments presently available (restricted to those freely available, open source and documented). For each simulation tool, its advantages and pitfalls are reviewed, with an aim to allow the reader to identify which simulator is appropriate for a given task. Finally, we provide a series of benchmark simulations of different types of networks of spiking neurons, including Hodgkin-Huxley type, integrate-and-fire models, interacting with current-based or conductance-based synapses, using clock-driven or event-driven integration strategies. The same set of models are implemented on the different simulators, and the codes are made available. The ultimate goal of this review is to provide a resource to facilitate identifying the appropriate integration strategy and simulation tool to use for a given modeling problem related to spiking neural networks.},
   keywords = {Algorithms
Animals
Computer Simulation
Electrophysiology
Humans
*Models, Neurological
Nerve Net/cytology/*physiology
Neurons/*physiology
Software
Synapses/physiology},
   year = {2007}
}

@article{INCF2007,
   author = {Djurfeldt, M. and Lansner, A.},
   title = {Workshop report: 1st {INCF} Workshop on Large-scale Modeling of the Nervous System.},
   journal = {Nature Precedings },
   volume = {(http://dx.doi.org/10.1038/npre.2007.262.1)},
   year = {2007}
}

@article{Morris1981,
title = "Voltage oscillations in the barnacle giant muscle fiber",
journal = "Biophysical Journal",
volume = "35",
number = "1",
pages = "193-213",
year = "1981",
issn = "0006-3495",
author = "C. Morris and H. Lecar"
}

@article{Destexhe2009,
   author = {Destexhe, Alain},
   affiliation = {CNRS Integrative and Computational Neuroscience Unit (UNIC) UPR2191 Gif-sur-Yvette France},
   title = {Self-sustained asynchronous irregular states and Up–Down states in thalamic, cortical and thalamocortical networks of nonlinear integrate-and-fire neurons},
   journal = {Journal of Computational Neuroscience},
   publisher = {Springer Netherlands},
   issn = {0929-5313},
   keyword = {Computer Science},
   pages = {493-506},
   volume = {27},
   issue = {3},
   year = {2009}
}



@article{Cannon2010,
    author = {Cannon, Robert C. AND O'Donnell, Cian AND Nolan, Matthew F.},
    journal = {PLoS Computational Biology},
    publisher = {Public Library of Science},
    title = {Stochastic Ion Channel Gating in Dendritic Neurons: Morphology Dependence and Probabilistic Synaptic Activation of Dendritic Spikes},
    year = {2010},
    month = {08},
    volume = {6},
    pages = {e1000886},
    number = {8}
}    

@ARTICLE{Druckmann2007,
 AUTHOR={Shaul Druckmann  and  Yoav Banitt  and  Albert A Gidon  and  Felix Sch\"{u}rmann  and  Henry Markram  and  Idan Segev},     
TITLE={A novel multiple objective optimization framework for constraining conductance-based neuron models by experimental data},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={1},      
YEAR={2007},      
NUMBER={0}
}

@article{Cuntz2010,
    author = {Cuntz, Hermann AND Forstner, Friedrich AND Borst, Alexander AND H\"{a}usser, Michael},
    journal = {PLoS Computational Biology},
    publisher = {Public Library of Science},
    title = {One Rule to Grow Them All: A General Theory of Neuronal Branching and Its Practical Application},
    year = {2010},
    month = {08},
    volume = {6},
    pages = {e1000877},
    abstract = {<title>Author Summary</title>
<p>More than a century has passed since RamÃ³n y Cajal presented a set of fundamental biological laws of neuronal branching. He described how the shape of the core elements of the neural circuitry - axons and dendrites - are constrained by physical parameters such as space, cytoplasmic volume, and conduction time. The existence of these laws enabled him to organize his histological observations, to formulate the neuron doctrine, and to infer directionality in signal flow in the nervous system. We show that Cajal's principles can be used computationally to generate synthetic neural circuits. These principles rigorously constrain the shape of real neuronal structures, providing direct validation of his theories. At the same time, this strategy provides us with a powerful set of tools for generating synthetic neurons, as well as a model-based approach for automated reconstructions of neuronal trees from confocal image stacks.</p>
},
    number = {8}
} 

@article{GleesonEtAl2010,
    author = {Gleeson, Padraig AND Crook, Sharon AND Cannon, Robert C. AND Hines, Michael L. AND Billings, Guy O. AND Farinella, Matteo AND Morse, Thomas M. AND Davison, Andrew P. AND Ray, Subhasis AND Bhalla, Upinder S. AND Barnes, Simon R. AND Dimitrova, Yoana D. AND Silver, R. Angus},
    journal = {PLoS Computational Biology},
    publisher = {Public Library of Science},
    title = {Neuro{ML}: A Language for Describing Data Driven Models of Neurons and Networks with a High Degree of Biological Detail},
    year = {2010},
    month = {06},
    volume = {6},
    pages = {e1000815},
    abstract = {<title>Author Summary</title>
<p>Computer modeling is becoming an increasingly valuable tool in the study of the complex interactions underlying the behavior of the brain. Software applications have been developed which make it easier to create models of neural networks as well as detailed models which replicate the electrical activity of individual neurons. The code formats used by each of these applications are generally incompatible however, making it difficult to exchange models and ideas between researchers. Here we present the structure of a neuronal model description language, NeuroML. This provides a way to express these complex models in a common format based on the underlying physiology, allowing them to be mapped to multiple applications. We have tested this language by converting published neuronal models to NeuroML format and comparing their behavior on a number of commonly used simulators. Creating a common, accessible model description format will expose more of the model details to the wider neuroscience community, thus increasing their quality and reliability, as for other Open Source software. NeuroML will also allow a greater "ecosystem" of tools to be developed for building, simulating and analyzing these complex neuronal systems.</p>
},
    number = {6},
} 

@misc{BrayXML,
   author = {Bray, T. and Paoli, J. and Sperberg-McQueen, C. M.},
   title = {Extensible {M}arkup {L}anguage ({XML}) 1.0},
   note = {{h}ttp://www.w3.org/TR/REC-xml},
   publisher = {W3C Recommendation},
   year = {1998}
}


@article{Davison2008,
   author = {Davison, A. P. and Bruderle, D. and Eppler, J. and Kremkow, J. and Muller, E. and Pecevski, D. and Perrinet, L. and Yger, P.},
   title = {Py{NN}: {A} Common Interface for Neuronal Network Simulators},
   journal = {Frontiers in Neuroinformatics},
   volume = {2},
   pages = {11},
   abstract = {Computational neuroscience has produced a diversity of software for simulations of networks of spiking neurons, with both negative and positive consequences. On the one hand, each simulator uses its own programming or configuration language, leading to considerable difficulty in porting models from one simulator to another. This impedes communication between investigators and makes it harder to reproduce and build on the work of others. On the other hand, simulation results can be cross-checked between different simulators, giving greater confidence in their correctness, and each simulator has different optimizations, so the most appropriate simulator can be chosen for a given modelling task. A common programming interface to multiple simulators would reduce or eliminate the problems of simulator diversity while retaining the benefits. PyNN is such an interface, making it possible to write a simulation script once, using the Python programming language, and run it without modification on any supported simulator (currently NEURON, NEST, PCSIM, Brian and the Heidelberg VLSI neuromorphic hardware). PyNN increases the productivity of neuronal network modelling by providing high-level abstraction, by promoting code sharing and reuse, and by providing a foundation for simulator-agnostic analysis, visualization and data-management tools. PyNN increases the reliability of modelling studies by making it much easier to check results on multiple simulators. PyNN is open-source software and is available from http://neuralensemble.org/PyNN.},
   year = {2008}
}

@article{Kumar2008,
author = {Kumar, Arvind and Rotter, Stefan and Aertsen, Ad}, 
title = {Conditions for Propagating Synchronous Spiking and Asynchronous Firing Rates in a Cortical Network Model}, 
volume = {28}, 
number = {20}, 
pages = {5268-5280}, 
year = {2008}, 
abstract ={Isolated feedforward networks (FFNs) of spiking neurons have been studied extensively for their ability to propagate transient synchrony and asynchronous firing rates, in the presence of activity independent synaptic background noise (Diesmann et al., 1999; van Rossum et al., 2002). In a biologically realistic scenario, however, the FFN should be embedded in a recurrent network, such that the activity in the FFN and the network activity may dynamically interact. Previously, transient synchrony propagating in an FFN was found to destabilize the dynamics of the embedding network (Mehring et al., 2003). Here, we show that by modeling synapses as conductance transients, rather than current sources, it is possible to embed and propagate transient synchrony in the FFN, without destabilizing the background network dynamics. However, the network activity has a strong impact on the type of activity that can be propagated in the embedded FFN. Global synchrony and high firing rates in the embedding network prohibit the propagation of both, synchronous and asynchronous spiking activity. In contrast, asynchronous low-rate network states support the propagation of both, synchronous spiking and asynchronous, but only low firing rates. In either case, spiking activity tends to synchronize as it propagates, challenging the feasibility to transmit information in asynchronous firing rates. Finally, asynchronous network activity allows to embed more than one FFN, with the amount of cross talk depending on the degree of overlap in the FFNs. This opens the possibility of computational mechanisms using transient synchrony among the activities in multiple FFNs.}, 
journal = {The Journal of Neuroscience} 
}


@book{NEST2002,
   author = {Diesmann, M and Gewaltig, M-O},
   title = {NEST: {A}n Environment for Neural Systems Simulations},
   publisher = {Gottingen: Ges. fur Wiss. Datenverarbeitung},
   volume = {Forschung und wisschenschaftliches Rechnen, Beitrage zum Heinz-Billing-Preis 2001},
   year = {2002}
}

@ARTICLE{Nomura2010,  
 AUTHOR={Taishin Nomura},     
TITLE={Towards Integration of Biological and Physiological Functions at Multiple Levels},      
JOURNAL={Frontiers in Physiology},      
VOLUME={1},      
YEAR={2010},      
NUMBER={0},        
ISSN={1664-042X},      
ABSTRACT={An aim of systems physiology today can be stated as to establish logical and quantitative bridges between phenomenological attributes of physiological entities such as cells and organs and physical attributes of biological entities, i.e., biological molecules, allowing us to describe and better understand physiological functions in terms of underlying biological functions. This article illustrates possible schema that can be used for promoting systems physiology by integrating quantitative knowledge of biological and physiological functions at multiple levels of time and space with the use of information technology infrastructure. Emphasis will be made for systematic, modular, hierarchical, and standardized descriptions of mathematical models of the functions and advantages for the use of them. }}

@article{Brian2008,
   author = {Goodman, D. and Brette, R.},
   title = {Brian: {A} simulator for spiking neural networks in {P}ython},
   journal = {Frontiers in Neuroinformatics},
   volume = {2},
   pages = {5},
   abstract = {"Brian" is a new simulator for spiking neural networks, written in Python (http://brian. di.ens.fr). It is an intuitive and highly flexible tool for rapidly developing new models, especially networks of single-compartment neurons. In addition to using standard types of neuron models, users can define models by writing arbitrary differential equations in ordinary mathematical notation. Python scientific libraries can also be used for defining models and analysing data. Vectorisation techniques allow efficient simulations despite the overheads of an interpreted language. Brian will be especially valuable for working on non-standard neuron models not easily covered by existing software, and as an alternative to using Matlab or C for simulations. With its easy and intuitive syntax, Brian is also very well suited for teaching computational neuroscience.},
   year = {2008}
}

@article{SBML2003,
   author = {Hucka, M. and Finney, A. and Sauro, H. M. and Bolouri, H. and Doyle, J. C. and Kitano, H. and Arkin, A. P. and Bornstein, B. J. and Bray, D. and Cornish-Bowden, A. and Cuellar, A. A. and Dronov, S. and Gilles, E. D. and Ginkel, M. and Gor, V. and Goryanin, II and Hedley, W. J. and Hodgman, T. C. and Hofmeyr, J. H. and Hunter, P. J. and Juty, N. S. and Kasberger, J. L. and Kremling, A. and Kummer, U. and Le Nov\`{e}re, N. and Loew, L. M. and Lucio, D. and Mendes, P. and Minch, E. and Mjolsness, E. D. and Nakayama, Y. and Nelson, M. R. and Nielsen, P. F. and Sakurada, T. and Schaff, J. C. and Shapiro, B. E. and Shimizu, T. S. and Spence, H. D. and Stelling, J. and Takahashi, K. and Tomita, M. and Wagner, J. and Wang, J.},
   title = {The {S}ystems {B}iology {M}arkup {L}anguage ({SBML}): a medium for representation and exchange of biochemical network models},
   journal = {Bioinformatics},
   volume = {19},
   number = {4},
   pages = {524-31},
   abstract = {MOTIVATION: Molecular biotechnology now makes it possible to build elaborate systems models, but the systems biology community needs information standards if models are to be shared, evaluated and developed cooperatively. RESULTS: We summarize the Systems Biology Markup Language (SBML) Level 1, a free, open, XML-based format for representing biochemical reaction networks. SBML is a software-independent language for describing models common to research in many areas of computational biology, including cell signaling pathways, metabolic pathways, gene regulation, and others. AVAILABILITY: The specification of SBML Level 1 is freely available from http://www.sbml.org/},
   keywords = {Database Management Systems
Databases, Factual
Documentation
Gene Expression Regulation/physiology
*Hypermedia
Information Storage and Retrieval/*methods
Metabolism/*physiology
*Models, Biological
Models, Chemical
*Programming Languages
Software
Software Design
Terminology
*Vocabulary, Controlled},
   year = {2003}
}


@article{CellML2004,
   author = {Lloyd, C. M. and Halstead, M. D. and Nielsen, P. F.},
   title = {Cell{ML}: its future, present and past},
   journal = {Progress in Biophysical Mololecular Bioliology},
   volume = {85},
   number = {2-3},
   pages = {433-50},
   abstract = {Advances in biotechnology and experimental techniques have lead to the elucidation of vast amounts of biological data. Mathematical models provide a method of analysing this data; however, there are two issues that need to be addressed: (1) the need for standards for defining cell models so they can, for example, be exchanged across the World Wide Web, and also read into simulation software in a consistent format and (2) eliminating the errors which arise with the current method of model publication. CellML has evolved to meet these needs of the modelling community. CellML is a free, open-source, eXtensible markup language based standard for defining mathematical models of cellular function. In this paper we summarise the structure of CellML, its current applications (including biological pathway and electrophysiological models), and its future development--in particular, the development of toolsets and the integration of ontologies.},
   keywords = {*Algorithms
Animals
*Cell Physiology
Computer Simulation/*standards/trends
Humans
Hypermedia/*standards/trends
Information Storage and Retrieval/*methods/standards/trends
*Models, Biological
*Programming Languages
Software/*standards/trends},
   year = {2004}
}


@article{Diwakar2010,
    author = {Diwakar, Shyam AND Lombardo, Paola AND Solinas, Sergio AND Naldi, Giovanni AND D'Angelo, Egidio},
    journal = {PLoS ONE},
    publisher = {Public Library of Science},
    title = {Local Field Potential Modeling Predicts Dense Activation in Cerebellar Granule Cells Clusters under {LTP} and {LTD} Control},
    year = {2011},
    month = {07},
    volume = {6},
    pages = {e21928},
    abstract = {
        <p>Local field-potentials (LFPs) are generated by neuronal ensembles and contain information about the activity of single neurons. Here, the LFPs of the cerebellar granular layer and their changes during long-term synaptic plasticity (LTP and LTD) were recorded in response to punctate facial stimulation in the rat in vivo. The LFP comprised a trigeminal (T) and a cortical (C) wave. T and C, which derived from independent granule cell clusters, co-varied during LTP and LTD. To extract information about the underlying cellular activities, the LFP was reconstructed using a repetitive convolution (ReConv) of the extracellular potential generated by a detailed multicompartmental model of the granule cell. The mossy fiber input patterns were determined using a Blind Source Separation (BSS) algorithm. The major component of the LFP was generated by the granule cell spike Na<sup>+</sup> current, which caused a powerful sink in the axon initial segment with the source located in the soma and dendrites. Reproducing the LFP changes observed during LTP and LTD required modifications in both release probability and intrinsic excitability at the mossy fiber-granule cells relay. Synaptic plasticity and Golgi cell feed-forward inhibition proved critical for controlling the percentage of active granule cells, which was 11% in standard conditions but ranged from 3% during LTD to 21% during LTP and raised over 50% when inhibition was reduced. The emerging picture is that of independent (but neighboring) trigeminal and cortical channels, in which synaptic plasticity and feed-forward inhibition effectively regulate the number of discharging granule cells and emitted spikes generating “dense” activity clusters in the cerebellar granular layer.</p>
      },
    number = {7}
}        



@article{Moose2008,
	AUTHOR={Ray, S. and Bhalla, U. S.},
		TITLE={Py{MOOSE}: interoperable scripting in {P}ython for {MOOSE}},
		JOURNAL={Frontiers in Neuroinformatics},
		VOLUME={2:6},
		YEAR={2008},
		NUMBER={2},
		ISSN={ISSN 1662-5196},
		ABSTRACT = {Python is emerging as a common scripting language for simulators. This opens up many possibilities for interoperability in the form of analysis, interfaces, and communications between simulators. We report the integration of Python scripting with the Multi-scale Object Oriented Simulation Environment (MOOSE).  MOOSE is a general-purpose simulation system for compartmental neuronal models and for models of signaling pathways based on chemical kinetics. We show how the Python-scripting version of MOOSE, PyMOOSE, combines the power of a compiled simulator with the versatility and ease of use of Python. We illustrate this by using Python numerical libraries to analyze MOOSE output online, and by developing a GUI in Python/Qt for a MOOSE simulation. Finally, we build and run a composite neuronal/signaling model that uses both the NEURON and MOOSE numerical engines, and Python as a bridge between the two. Thus PyMOOSE has a high degree of interoperability with analysis routines, with graphical toolkits, and with other simulators.}
}

@article{Neurospaces2003,
   author = {Cornelis, H. and De Schutter, E.},
   title = {Neuro{S}paces: separating modeling and simulation},
   journal = {Neurocomputing},
		YEAR={2003},
   volume = {52},
   number = {4},
   pages = {227-231}
}

@article{DeSchutterI1994,
   author = {De Schutter, E. and Bower, J. M.},
   title = {An active membrane model of the cerebellar {P}urkinje cell. {I}. Simulation of current clamps in slice},
   journal = {Journal of Neurophysiology},
   volume = {71},
   number = {1},
   pages = {375-400},
   abstract = {1. A detailed compartmental model of a cerebellar Purkinje cell with active dendritic membrane was constructed. The model was based on anatomic reconstructions of single Purkinje cells and included 10 different types of voltage-dependent channels described by Hodgkin-Huxley equations, derived from Purkinje cell-specific voltage-clamp data where available. These channels included a fast and persistent Na+ channel, three voltage-dependent K+ channels, T-type and P-type Ca2+ channels, and two types of Ca(2+)-activated K+ channels. 2. The ionic channels were distributed differentially over three zones of the model, with Na+ channels in the soma, fast K+ channels in the soma and main dendrite, and Ca2+ channels and Ca(2+)-activated K+ channels in the entire dendrite. Channel densities in the model were varied until it could reproduce Purkinje cell responses to current injections in the soma or dendrite, as observed in slice recordings. 3. As in real Purkinje cells, the model generated two types of spiking behavior. In response to small current injections the model fired exclusively fast somatic spikes. These somatic spikes were caused by Na+ channels and repolarized by the delayed rectifier. When higher-amplitude current injections were given, sodium spiking increased in frequency until the model generated large dendritic Ca2+ spikes. Analysis of membrane currents underlying this behavior showed that these Ca2+ spikes were caused by the P-type Ca2+ channel and repolarized by the BK-type Ca(2+)-activated K+ channel. As in pharmacological blocking experiments, removal of Na+ channels abolished the fast spikes and removal of Ca2+ channels removed Ca2+ spiking. 4. In addition to spiking behavior, the model also produced slow plateau potentials in both the dendrite and soma. These longer-duration potentials occurred in response to both short and prolonged current steps. Analysis of the model demonstrated that the plateau potentials in the soma were caused by the window current component of the fast Na+ current, which was much larger than the current through the persistent Na+ channels. Plateau potentials in the dendrite were carried by the same P-type Ca2+ channel that was also responsible for Ca2+ spike generation. The P channel could participate in both model functions because of the low-threshold K2-type Ca(2+)-activated K+ channel, which dynamically changed the threshold for dendritic spike generation through a negative feedback loop with the activation kinetics of the P-type Ca2+ channel. 5. These model responses were robust to changes in the densities of all of the ionic channels.(ABSTRACT TRUNCATED AT 400 WORDS)},
   keywords = {Animals
Calcium/physiology
Calcium Channels/physiology
Dendrites/metabolism/physiology
Electrophysiology
Guinea Pigs
In Vitro
Ion Channels/*physiology
Membrane Potentials/physiology
Models, Neurological
Potassium Channels/physiology
Purkinje Cells/*physiology
Rats
Research Support, U.S. Gov't, Non-P.H.S.
Research Support, U.S. Gov't, P.H.S.
Sodium Channels/physiology
Synapses/physiology
Temperature},
   year = {1994}
}

@article{DestexhePare99,
   author = {Destexhe, A. and Pare, D.},
   title = {Impact of network activity on the integrative properties of neocortical pyramidal neurons in vivo},
   journal = {Journal of Neurophysiology},
   volume = {81},
   number = {4},
   pages = {1531-47},
   abstract = {During wakefulness, neocortical neurons are subjected to an intense synaptic bombardment. To assess the consequences of this background activity for the integrative properties of pyramidal neurons, we constrained biophysical models with in vivo intracellular data obtained in anesthetized cats during periods of intense network activity similar to that observed in the waking state. In pyramidal cells of the parietal cortex (area 5-7), synaptic activity was responsible for an approximately fivefold decrease in input resistance (Rin), a more depolarized membrane potential (Vm), and a marked increase in the amplitude of Vm fluctuations, as determined by comparing the same cells before and after microperfusion of tetrodotoxin (TTX). The model was constrained by measurements of Rin, by the average value and standard deviation of the Vm measured from epochs of intense synaptic activity recorded with KAc or KCl-filled pipettes as well as the values measured in the same cells after TTX. To reproduce all experimental results, the simulated synaptic activity had to be of relatively high frequency (1-5 Hz) at excitatory and inhibitory synapses. In addition, synaptic inputs had to be significantly correlated (correlation coefficient approximately 0.1) to reproduce the amplitude of Vm fluctuations recorded experimentally. The presence of voltage-dependent K+ currents, estimated from current-voltage relations after TTX, affected these parameters by <10%. The model predicts that the conductance due to synaptic activity is 7-30 times larger than the somatic leak conductance to be consistent with the approximately fivefold change in Rin. The impact of this massive increase in conductance on dendritic attenuation was investigated for passive neurons and neurons with voltage-dependent Na+/K+ currents in soma and dendrites. In passive neurons, correlated synaptic bombardment had a major influence on dendritic attenuation. The electrotonic attenuation of simulated synaptic inputs was enhanced greatly in the presence of synaptic bombardment, with distal synapses having minimal effects at the soma. Similarly, in the presence of dendritic voltage-dependent currents, the convergence of hundreds of synaptic inputs was required to evoke action potentials reliably. In this case, however, dendritic voltage-dependent currents minimized the variability due to input location, with distal apical synapses being as effective as synapses on basal dendrites. In conclusion, this combination of intracellular and computational data suggests that, during low-amplitude fast electroencephalographic activity, neocortical neurons are bombarded continuously by correlated synaptic inputs at high frequency, which significantly affect their integrative properties. A series of predictions are suggested to test this model.},
   keywords = {Action Potentials/drug effects/physiology
Adrenergic alpha-Agonists/pharmacology
Animals
Awareness/physiology
Cats
Dendrites/drug effects/physiology
Electric Conductivity
Electroencephalography
Excitatory Amino Acid Antagonists/pharmacology
Excitatory Postsynaptic Potentials/drug effects/physiology
Ketamine/pharmacology
Neocortex/*cytology/physiology
*Nerve Net
Neural Pathways
Pyramidal Cells/*physiology
Research Support, Non-U.S. Gov't
Synapses/drug effects/physiology
Tetrodotoxin/pharmacology
Xylazine/pharmacology},
   year = {1999}
}


@article{MainenEtAl95,
   author = {Mainen, Z. F. and Joerges, J. and Huguenard, J. R. and Sejnowski, T. J.},
   title = {A model of spike initiation in neocortical pyramidal neurons},
   journal = {Neuron},
   volume = {15},
   number = {6},
   pages = {1427-39},
   abstract = {Neocortical pyramidal cells possess voltage-dependent dendritic sodium channels that promote propagation of action potentials into the dendritic tree but paradoxically may fail to originate dendritic spikes. A biophysical model was constructed to reconcile these observations with known anatomical and physiological properties. When dendritic and somatic sodium channel densities compatible with electrophysiological measurements were combined with much higher densities in the axon initial segment then, regardless of the site of stimulation, spikes initiated at the initial segment and subsequently invaded the dendrites. The lower initial segment threshold arose from high current density and electrical isolation from the soma. Failure of dendritic channels to initiate spikes was due to inactivation and source-load considerations, which were more favorable for conduction of back-propagated spikes.},
   keywords = {Action Potentials
Animals
Axons/physiology
Dendrites/physiology
Models, Neurological
Pyramidal Cells/*physiology
Rats
Research Support, Non-U.S. Gov't
Research Support, U.S. Gov't, P.H.S.},
   year = {1995}
}


@article{JarskyEtAl05,
   author = {Jarsky, T. and Roxin, A. and Kath, W. L. and Spruston, N.},
   title = {Conditional dendritic spike propagation following distal synaptic activation of hippocampal {CA}1 pyramidal neurons},
   journal = {Nature Neuroscience},
   volume = {8},
   number = {12},
   pages = {1667-76},
   abstract = {The perforant-path projection to the hippocampus forms synapses in the apical tuft of CA1 pyramidal neurons. We used computer modeling to examine the function of these distal synaptic inputs, which led to three predictions that we confirmed in experiments using rat hippocampal slices. First, activation of CA1 neurons by the perforant path is limited, a result of the long distance between these inputs and the soma. Second, activation of CA1 neurons by the perforant path depends on the generation of dendritic spikes. Third, the forward propagation of these spikes is unreliable, but can be facilitated by modest activation of Schaffer-collateral synapses in the upper apical dendrites. This 'gating' of dendritic spike propagation may be an important activation mode of CA1 pyramidal neurons, and its modulation by neurotransmitters or long-term, activity-dependent plasticity may be an important feature of dendritic integration during mnemonic processing in the hippocampus.},
   keywords = {Action Potentials/*physiology
Animals
Dendrites/*physiology
Hippocampus/cytology/*physiology
Long-Term Depression (Physiology)/physiology
Long-Term Potentiation/physiology
Male
Memory/physiology
Neural Inhibition/physiology
Neural Networks (Computer)
Neural Pathways/*physiology
Neurotransmitter Agents/metabolism
Organ Culture Techniques
Patch-Clamp Techniques
Perforant Pathway/physiology
Pyramidal Cells/*physiology
Rats
Rats, Wistar
Research Support, N.I.H., Extramural
Research Support, U.S. Gov't, Non-P.H.S.
Synaptic Transmission/*physiology},
   year = {2005}
}


@article{MiglioreEtAl95,
   author = {Migliore, M. and Cook, E. P. and Jaffe, D. B. and Turner, D. A. and Johnston, D.},
   title = {Computer simulations of morphologically reconstructed {CA}3 hippocampal neurons},
   journal = {Journal of Neurophysiology},
   volume = {73},
   number = {3},
   pages = {1157-68},
   abstract = {1. We tested several hypotheses with respect to the mechanisms and processes that control the firing characteristics and determine the spatial and temporal dynamics of intracellular Ca2+ in CA3 hippocampal neurons. In particular, we were interested to know 1) whether bursting and nonbursting behavior of CA3 neurons could be accounted for in a morphologically realistic model using a number of the known ionic conductances; 2) whether such a model is robust across different cell morphologies; 3) whether some particular nonuniform distribution of Ca2+ channels is required for bursting; and 4) whether such a model can reproduce the magnitude and spatial distribution of intracellular Ca2+ transients determined from fluorescence imaging studies and can predict reasonable intracellular Ca2+ concentration ([Ca2+]i) distribution for CA3 neurons. 2. For this purpose we have developed a highly detailed model of the distribution and densities of membrane ion channels in hippocampal CA3 bursting and nonbursting pyramidal neurons. This model reproduces both the experimentally observed firing modes and the dynamics of intracellular Ca2+. 3. The kinetics of the membrane ionic conductances are based on available experimental data. This model incorporates a single Na+ channel, three Ca2+ channels (CaN, CaL, and CaT), three Ca(2+)-independent K+ channels (KDR, KA, and KM), two Ca(2+)-dependent K+ channels (KC and KAHP), and intracellular Ca(2+)-related processes such as buffering, pumping, and radial diffusion. 4. To test the robustness of the model, we applied it to six different morphologically accurate reconstructions of CA3 hippocampal pyramidal neurons. In every neuron, Ca2+ channels, Ca(2+)-related processes, and Ca(2+)-dependent K+ channels were uniformly distributed over the entire cell. Ca(2+)-independent K+ channels were placed on the soma and the proximal apical dendrites. For each reconstructed cell we were able to reproduce bursting and nonbursting firing characteristics as well as Ca2+ transients and distributions for both somatic and synaptic stimulations. 5. Our simulation results suggest that CA3 pyramidal cell bursting behavior does not require any special distribution of Ca(2+)-dependent channels and mechanisms. Furthermore, a simple increase in the Ca(2+)-independent K+ conductances is sufficient to change the firing mode of our CA3 neurons from bursting to nonbursting. 6. The model also displays [Ca2+]i transients and distributions that are consistent with fluorescent imaging data. Peak [Ca2+]i distribution for synaptic stimulation of the nonbursting model is broader when compared with somatic stimulation. Somatic stimulation of the bursting model shows a broader distribution in [Ca2+]i when compared with the nonbursting model.(ABSTRACT TRUNCATED AT 400 WORDS)},
   keywords = {Calcium
*Computer Simulation
Hippocampus/*physiology
Kinetics
Mathematics
*Neural Networks (Computer)
Neurons/physiology
Research Support, Non-U.S. Gov't
Research Support, U.S. Gov't, P.H.S.
Synapses
Time Factors},
   year = {1995}
}


@article{Poirazi2003,
   author = {Poirazi, P. and Brannon, T. and Mel, B. W.},
   title = {Pyramidal neuron as two-layer neural network},
   journal = {Neuron},
   volume = {37},
   number = {6},
   pages = {989-99},
   abstract = {The pyramidal neuron is the principal cell type in the mammalian forebrain, but its function remains poorly understood. Using a detailed compartmental model of a hippocampal CA1 pyramidal cell, we recorded responses to complex stimuli consisting of dozens of high-frequency activated synapses distributed throughout the apical dendrites. We found the cell's firing rate could be predicted by a simple formula that maps the physical components of the cell onto those of an abstract two-layer "neural network." In the first layer, synaptic inputs drive independent sigmoidal subunits corresponding to the cell's several dozen long, thin terminal dendrites. The subunit outputs are then summed within the main trunk and cell body prior to final thresholding. We conclude that insofar as the neural code is mediated by average firing rate, a two-layer neural network may provide a useful abstraction for the computing function of the individual pyramidal neuron.},
   keywords = {Biophysics
Calcium/metabolism
Dendrites/physiology
Electric Conductivity
Electrophysiology
Mathematics
Models, Biological
Nerve Net/*physiology/ultrastructure
Potassium Channels/physiology
Pyramidal Cells/*physiology/ultrastructure
Research Support, Non-U.S. Gov't
Research Support, U.S. Gov't, Non-P.H.S.
Sodium Channels/physiology
Synapses/physiology},
   year = {2003}
}


@article{VetterEtAl01,
   author = {Vetter, P. and Roth, A. and H\"{a}usser, M.},
   title = {Propagation of action potentials in dendrites depends on dendritic morphology},
   journal = {Journal of Neurophysiology},
   volume = {85},
   number = {2},
   pages = {926-37},
   abstract = {Action potential propagation links information processing in different regions of the dendritic tree. To examine the contribution of dendritic morphology to the efficacy of propagation, simulations were performed in detailed reconstructions of eight different neuronal types. With identical complements of voltage-gated channels, different dendritic morphologies exhibit distinct patterns of propagation. Remarkably, the range of backpropagation efficacies observed experimentally can be reproduced by the variations in dendritic morphology alone. Dendritic geometry also determines the extent to which modulation of channel densities can affect propagation. Thus in Purkinje cells and dopamine neurons, backpropagation is relatively insensitive to changes in channel densities, whereas in pyramidal cells, backpropagation can be modulated over a wide range. We also demonstrate that forward propagation of dendritically initiated action potentials is influenced by morphology in a similar manner. We show that these functional consequences of the differences in dendritic geometries can be explained quantitatively using simple anatomical measures of dendritic branching patterns, which are captured in a reduced model of dendritic geometry. These findings indicate that differences in dendritic geometry act in concert with differences in voltage-gated channel density and kinetics to generate the diversity in dendritic action potential propagation observed between neurons. They also suggest that changes in dendritic geometry during development and plasticity will critically affect propagation. By determining the spatial pattern of action potential signaling, dendritic morphology thus helps to define the size and interdependence of functional compartments in the neuron.},
   keywords = {Action Potentials/physiology
Animals
Computer Simulation
Dendrites/*physiology/*ultrastructure
Mathematics
Models, Neurological
Neurons/classification/physiology
Potassium Channels/metabolism
Rats
Research Support, Non-U.S. Gov't
Sodium Channels/metabolism},
   year = {2001}
}


@article{Ascoli06,
   author = {Ascoli, G. A.},
   title = {Mobilizing the base of neuroscience data: the case of neuronal morphologies},
   journal = {Nature Reviews Neuroscience},
   volume = {7},
   number = {4},
   pages = {318-24},
   abstract = {Despite the explosive growth of bioinformatics, data sharing has not yet become routine in neuroscience, possibly because of several broad-spanning issues, from data heterogeneity to privacy regulations. We present the case of neuronal morphology as an ideal example of shareable data. Drawing from recent experience, we argue that the tremendous research potential of existing (and largely unused) digital reconstructions should diffuse any reticence to sharing this type of data.},
   keywords = {Animals
*Computational Biology
Cooperative Behavior
Databases, Factual/*supply & distribution
Humans
Neurons/*cytology/physiology
*Neurosciences/methods/statistics & numerical data/trends
Research Support, N.I.H., Extramural
Research Support, U.S. Gov't, Non-P.H.S.
Signal Processing, Computer-Assisted},
   year = {2006}
}


@article{Cannon2002,
   author = {Cannon, R. C. and Howell, F. W. and Goddard, N. H. and De Schutter, E.},
   title = {Non-curated distributed databases for experimental data and models in neuroscience},
   journal = {Network},
   volume = {13},
   number = {3},
   pages = {415-28},
   abstract = {Neuroscience is generating vast amounts of highly diverse data which is of potential interest to researchers beyond the laboratories in which it is collected. In particular, quantitative neuroanatomical data is relevant to a wide variety of areas, including studies of development, aging, pathology and in biophysically oriented computational modelling. Moreover, the relatively discrete and well-defined nature of the data make it an ideal application for developing systems designed to facilitate data archiving, sharing and reuse. At present, the only widely used forms of dissemination are figures and tables in published papers which suffer from inaccessibility and the loss of machine readability. They may also present only an averaged or otherwise selected subset of the available data. Numerous database projects are in progress to address these shortcomings. They employ a variety of architectures and philosophies, each with its own merits and disadvantages. One axis on which they may be distinguished is the degree of top-down control, or curation, involved in data entry. Here we consider one extreme of this scale in which there is no curation, minimal standardization and a wide degree of freedom in the form of records used to document data. Such a scheme has advantages in the ease of database creation and in the equitable assignment of perceived intellectual property by keeping the control of data in the hands of the experts who collected it. It does, however, require a more sophisticated infrastructure than conventional databases since the software must be capable of organizing diverse and differently documented data sets in an effective way. Several components of a software system to provide this infrastructure are now in place. Examples are presented, showing how these tools can be used to archive and publish neuronal morphology data, and how they can give an integrated view of data stored at many different sites.},
   keywords = {Animals
Databases, Factual/*standards/trends
Humans
*Models, Neurological
Neuroanatomy/methods
Neurosciences/methods/*standards/trends
Research Support, Non-U.S. Gov't},
   year = {2002}
}



@article{Cannon1998,
   author = {Cannon, R. C. and Turner, D. A. and Pyapali, G. K. and Wheal, H. V.},
   title = {An on-line archive of reconstructed hippocampal neurons},
   journal = {Journal of Neuroscience Methods},
   volume = {84},
   number = {1-2},
   pages = {49-54},
   abstract = {We have developed an on-line archive of neuronal geometry to encourage the use of realistic dendritic structures in morphometry and for neuronal modeling, located at web address www.neuro.soton.ac.uk. Initially we have included full three-dimensional representations of 87 neurons from the hippocampus, obtained following intracellular staining with biocytin and reconstruction using Neurolucida. The archive system includes a structure editor for correcting any departures from valid branching geometry and which allows simple errors in the digitisation to be corrected. The editor employs a platform-independent file format which enforces the constraints that there should be no isolated branches and no closed loops. It also incorporates software for interconversion between the archive format and those used by various neuronal reconstruction and modelling packages. The raw data from digitisation software can be included in the archive as well as edited reconstructions and any further information available. Cross-referenced tables and indexes are updated automatically and are sorted according to a number of fields including the cell type, contributor, submission date and published reference. Both the archive and the structure editor should facilitate the quantitative use of full three-dimensional reconstructions of neurons from the hippocampus and other brain regions.},
   keywords = {Animals
Databases, Factual
Dendrites/*ultrastructure
Hippocampus/*cytology
Image Processing, Computer-Assisted/methods
Internet
Lysine/analogs & derivatives
Models, Anatomic
Models, Neurological
Neurons/*cytology/ultrastructure
Pyramidal Cells/*cytology/ultrastructure
Reproducibility of Results
Research Support, Non-U.S. Gov't
Research Support, U.S. Gov't, Non-P.H.S.
Research Support, U.S. Gov't, P.H.S.
Software},
   year = {1998}
}



@article{SanthakumarEtAl05,
   author = {Santhakumar, V. and Aradi, I. and Soltesz, I.},
   title = {Role of mossy fiber sprouting and mossy cell loss in hyperexcitability: a network model of the dentate gyrus incorporating cell types and axonal topography},
   journal = {Journal of Neurophysiology},
   volume = {93},
   number = {1},
   pages = {437-53},
   abstract = {Mossy cell loss and mossy fiber sprouting are two characteristic consequences of repeated seizures and head trauma. However, their precise contributions to the hyperexcitable state are not well understood. Because it is difficult, and frequently impossible, to independently examine using experimental techniques whether it is the loss of mossy cells or the sprouting of mossy fibers that leads to dentate hyperexcitability, we built a biophysically realistic and anatomically representative computational model of the dentate gyrus to examine this question. The 527-cell model, containing granule, mossy, basket, and hilar cells with axonal projections to the perforant-path termination zone, showed that even weak mossy fiber sprouting (10-15% of the strong sprouting observed in the pilocarpine model of epilepsy) resulted in the spread of seizure-like activity to the adjacent model hippocampal laminae after focal stimulation of the perforant path. The simulations also indicated that the spatially restricted, lamellar distribution of the sprouted mossy fiber contacts reported in in vivo studies was an important factor in sustaining seizure-like activity in the network. In contrast to the robust hyperexcitability-inducing effects of mossy fiber sprouting, removal of mossy cells resulted in decreased granule cell responses to perforant-path activation in agreement with recent experimental data. These results indicate the crucial role of mossy fiber sprouting even in situations where there is only relatively weak mossy fiber sprouting as is the case after moderate concussive experimental head injury.},
   keywords = {Animals
Cell Count/methods
Cell Survival
Comparative Study
Computer Simulation
Dentate Gyrus/*cytology
Dose-Response Relationship, Radiation
Electric Stimulation
Membrane Potentials/physiology/radiation effects
Models, Neurological
Mossy Fibers, Hippocampal/*physiology
Neural Conduction/physiology
Neural Inhibition/physiology
*Neural Networks (Computer)
Neurons/*classification/cytology/*physiology
Research Support, U.S. Gov't, P.H.S.
Seizures/*physiopathology
Synaptic Transmission/physiology
Time Factors},
   year = {2005}
}


@article{Song2000,
author={Song, S. and Miller, K. D. and Abbott, L. F.},
title={Competitive {H}ebbian learning through spike-timing-dependent synaptic plasticity},
journal={Nature Neuroscience},
volum={3},
year={2000},
pages={919-926},
}

@article{Tsodyks1997,
author={Tsodyks, M. V. and Markram, H.},
title={The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability},
journal={Proceedings of the National Academy of Sciences USA},
volum={94},
pages={719-723},
year={1997},
}

@article{Tsodyks2000,
author={Tsodyks, M. and Uziel, A. and Markram, H.},
title={Synchrony generation in recurrent networks with frequency-dependent synapses},
journal={Journal of Neuroscience},
volum={20},
pages={RC50},
year={2000},
}

@article{Rhodes01,
author = {Rhodes, Paul A and Llinas, Rodolfo R},
title={{Apical tuft input efficacy in layer 5 pyramidal cells from rat visual cortex}},
journal = {The Journal of Physiology},
volume = {536},
number = {1},
pages = {167-187},
year = {2001},
abstract = {

The integration of synaptic inputs to the apical dendrite of layer 5 neocortical pyramidal cells was studied using compartment model simulations. The goal was to characterize the generation of regenerative responses to synaptic inputs under two conditions: (a) where there was an absence of background synaptic input, and (b) when the entire cell surface was subjected to a uniform blanket of synaptic background conductance such that somatic input resistance was reduced 5-fold.
Dendritic morphology corresponded to a layer 5 thick-trunked pyramidal cell from rat primary visual cortex at postnatal day 28 (P28), with distribution of dendritic active currents guided by the electrophysiological characteristics of the apical trunk reported in this cell type. Response characteristics for two dendritic channel distributions were compared, one of which supported Ca spikes in the apical dendrite.
In the absence of background, synaptic input to the apical tuft was surprisingly effective in eliciting somatic firing when compared with input to apical oblique branches. This result obtained even when the tuft membrane was the least excitable in the dendritic tree.
The special efficacy of tuft input arose because its electrotonic characteristics favour development of a sustained depolarization which charged the apex of the apical trunk to its firing threshold; once initiated in the distal trunk, firing propagated inward to the soma. This mechanism did not depend upon the presence of depolarizing channels in tuft membrane, but did require an excitable apical trunk.
Rather than disconnect the tuft, background synaptic conductance enhanced the efficacy advantage enjoyed by input arriving there. This counterintuitive result arose because background reduced the subthreshold spread of voltage, and so diminished the ability of the excitation of various individual oblique branches to combine to charge the relatively thick adjacent trunk. In contrast, drive from the depolarized tuft is exerted at a single critical point, the apex of the distal trunk, and so was relatively undiminished by the background. Further, once initiation at the apex occurred, background had little effect on inward propagation along the trunk.
We conclude that synaptic input to the apical tuft of layer 5 cells may be unexpectedly effective in triggering cell firing . The advantage in efficacy was not dependent upon the characteristics of tuft membrane excitability, but rather stemmed from the geometry of the tuft and its junction with the distal apical trunk. The efficacy of tuft input was, however, critically dependent upon inward propagation, suggesting that modulation of membrane currents which affect propagation in the apical trunk might sensitively control the efficacy of tuft input.


}
}

@article{TraubEtAl05,
   author = {Traub, R. D. and Contreras, D. and Cunningham, M. O. and Murray, H. and LeBeau, F. E. and Roopun, A. and Bibbig, A. and Wilent, W. B. and Higley, M. J. and Whittington, M. A.},
   title = {Single-column thalamocortical network model exhibiting gamma oscillations, sleep spindles, and epileptogenic bursts},
   journal = {Journal of Neurophysiology},
   volume = {93},
   number = {4},
   pages = {2194-232},
   abstract = {To better understand population phenomena in thalamocortical neuronal ensembles, we have constructed a preliminary network model with 3,560 multicompartment neurons (containing soma, branching dendrites, and a portion of axon). Types of neurons included superficial pyramids (with regular spiking [RS] and fast rhythmic bursting [FRB] firing behaviors); RS spiny stellates; fast spiking (FS) interneurons, with basket-type and axoaxonic types of connectivity, and located in superficial and deep cortical layers; low threshold spiking (LTS) interneurons, which contacted principal cell dendrites; deep pyramids, which could have RS or intrinsic bursting (IB) firing behaviors, and endowed either with nontufted apical dendrites or with long tufted apical dendrites; thalamocortical relay (TCR) cells; and nucleus reticularis (nRT) cells. To the extent possible, both electrophysiology and synaptic connectivity were based on published data, although many arbitrary choices were necessary. In addition to synaptic connectivity (by AMPA/kainate, NMDA, and GABA(A) receptors), we also included electrical coupling between dendrites of interneurons, nRT cells, and TCR cells, and--in various combinations--electrical coupling between the proximal axons of certain cortical principal neurons. Our network model replicates several observed population phenomena, including 1) persistent gamma oscillations; 2) thalamocortical sleep spindles; 3) series of synchronized population bursts, resembling electrographic seizures; 4) isolated double population bursts with superimposed very fast oscillations (>100 Hz, "VFO"); 5) spike-wave, polyspike-wave, and fast runs (about 10 Hz). We show that epileptiform bursts, including double and multiple bursts, containing VFO occur in rat auditory cortex in vitro, in the presence of kainate, when both GABA(A) and GABA(B) receptors are blocked. Electrical coupling between axons appears necessary (as reported previously) for persistent gamma and additionally plays a role in the detailed shaping of epileptogenic events. The degree of recurrent synaptic excitation between spiny stellate cells, and their tendency to fire throughout multiple bursts, also appears critical in shaping epileptogenic events.},
   keywords = {Action Potentials/physiology
Animals
Biological Clocks/*physiology
Cerebral Cortex/*physiology
Comparative Study
Epilepsy/*physiopathology
Male
*Models, Neurological
*Nerve Net
Rats
Rats, Sprague-Dawley
Rats, Wistar
Sleep/*physiology
Thalamus/*physiology},
   year = {2005}
}

@book{XPPAUT,
 author = {Ermentrout, Bard},
 title = {Simulating, Analyzing, and Animating Dynamical Systems: A Guide To {XPPAUT} for Researchers and Students},
 year = {2002},
 isbn = {0898715067},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 }
 
 
@book {HippocampalMicrocircuits,
   title = {Hippocampal Microcircuits: {A} Computational Modeler's Resource Book},
   series = {Springer Series in Computational Neuroscience},
   editor = {Cutsuridis, Vassilis and Graham, Bruce and Cobb, Stuart and Vida, Imre},
   publisher = {Springer New York},
   isbn = {978-1-4419-0995-4},
   keyword = {Biomedicine},
   year = {2010}
}
 
 
@article{Gardner2004,
   author = {Gardner, D.},
   title = {Neurodatabase.org: networking the microelectrode},
   journal = {Nature Neuroscience},
   volume = {7},
   number = {5},
   pages = {486-487},
   year = {2004}
}

@article{NeuroMorpho,
   author = {Ascoli, G. A. and Donohue, D. E. and Halavi, M.},
   title = {Neuro{M}orpho.org: a central resource for neuronal morphologies},
   journal = {Journal of Neuroscience},
   volume = {27},
   number = {35},
   pages = {9247-51},
   year = {2007}
}

@article{Hines08,
   author = {Hines, M. L. and Carnevale, N. T.},
   title = {Translating network models to parallel hardware in {NEURON}},
   journal = {Journal of Neuroscience Methods},
   volume = {169},
   number = {2},
   pages = {425-55},
   keywords = {Computer Simulation
*Computer Systems
*Models, Neurological
*Neural Networks (Computer)
Neurons/*physiology
Programming Languages
Software},
   year = {2008}
}



@article{Migliore06,
   author = {Migliore, M. and Cannia, C. and Lytton, W. and Markram, Henry and Hines, M.},
   title = {Parallel network simulations with {NEURON}},
   journal = {Journal of Computational Neuroscience},
   volume = {12},
   number = {2},
   pages = {119-129},
   year = {2006}
}
   

@article{HinesSplit08,
   author = {Hines, M. L. and Eichner, H. and Sch\"{u}rmann, F.},
   title = {Neuron splitting in compute-bound parallel network simulations enables runtime scaling with twice as many processors.},
   journal = {Journal of Computational Neuroscience},
   volume = {25},
   number = {1},
   pages = {203-10},
   keywords = {Cerebral Cortex
Computer Simulation
Dentate Gyrus
Neural Networks (Computer)
Neurons
Normal Distribution
Thalamic Nuclei},
   year = {2008}
}
  
  

@article{NMODL,
author = {Hines, M. L. and Carnevale, N. T.},
title = {Expanding {NEURON}'s Repertoire of Mechanisms with {NMODL}},
journal = {Neural Computationation},
volume = {12},
number = {5},
pages = {995-1007},
year = {2000}
}

  
@article{BioModels,
   author = {Le Nov\`{e}re, N. and Bornstein, B. and Broicher, A. and Courtot, M. and Donizelli, M. and Dharuri, H. and Li, L. and Sauro, H. and Schilstra, M. and Shapiro, B. and Snoep, J. L. and Hucka, M.},
   title = {Bio{M}odels Database: a free, centralized database of curated, published, quantitative kinetic models of biochemical and cellular systems},
   journal = {Nucleic Acids Res},
   volume = {34},
   number = {Database issue},
   pages = {D689-91},
   year = {2006}
}

@ARTICLE{BioModels2010,
  author  = {Li, Chen and Donizelli, Marco and Rodriguez, Nicolas and Dharuri, Harish and Endler, Lukas and Chelliah, Vijayalakshmi and Li, Lu and He, Enuo and Henry, Arnaud and Stefan, Melanie I. and Snoep, Jacky L. and Hucka, Michael and Le Nov{\`e}re, Nicolas and Laibe, Camille},
  title   = {{Bio{M}odels Database: An enhanced, curated and annotated resource for published quantitative kinetic models.}},
  journal = {BMC Systems Biology},
  year    = {2010},
  month   = {Jun},
  volume  = {4},
  pages   = {92},
  pmid    = {20587024}
}


@article{CellMLMR,
   author = {Lloyd, C. M. and Lawson, J. R. and Hunter, P. J. and Nielsen, P. F.},
   title = {The {C}ell{ML} {M}odel {R}epository.},
   journal = {Bioinformatics},
   volume = {24},
   number = {18},
   pages = {2122-3},
   year = {2008}
}

@article{Markram06,
   author = {Markram, Henry},
   title = {The {B}lue {B}rain {P}roject},
   journal = {Nature Reviews Neuroscience},
   volume = {7},
   number = {2},
   pages = {153-160},
   year = {2006}
}


@article{DIADEMchallenge,
   author = {Gillette, T. A. and Brown, K. M. and Svoboda, K. and Liu, Y. and Ascoli, G. A.},
   title = {{DIADEM}challenge.Org: A Compendium of Resources Fostering the Continuous Development of Automated Neuronal Reconstruction.},
   journal = {Neuroinformatics},
   volume = {(in press)},
   year = {2011}
}

@article{Morrison05,
   author = {Morrison, A. and Mehring, C. and Geisel, T. and Aertsen, A. D. and Diesmann, M.},
   title = {Advancing the boundaries of high-connectivity network simulation with distributed computing.},
   journal = {Neural Computation},
   volume = {17},
   number = {8},
   pages = {1776-801},
   year = {2005}
}

@article{HinesSplit2proc,
   author = {Hines, M. L. and Eichner, H. and Sch\"{u}rmann, F.},
   title = {Neuron splitting in compute-bound parallel network simulations enables runtime scaling with twice as many processors.},
   journal = {Journal of Computational Neuroscience},
   volume = {25},
   number = {1},
   pages = {203-10},
   year = {2008}
}

@article{HinesSplit,
   author = {Hines, M. L. and Markram, H. and Sch\"{u}rmann, F.},
   title = {Fully implicit parallel simulation of single neurons.},
   journal = {Journal of Computational Neuroscience},
   volume = {25},
   number = {3},
   pages = {439-48},
   year = {2008}
}


@article{Solinas07a,
   author = {Solinas, S. and Forti, L. and Cesana, E. and Mapelli, J. and De Schutter, E. and D'Angelo, E.},
   title = {Computational reconstruction of pacemaking and intrinsic electroresponsiveness in cerebellar {G}olgi cells.},
   journal = {Frontiers in Cellular Neuroscience},
   volume = {1},
   pages = {2},
   year = {2007}
}

@article{Solinas07b,
   author = {Solinas, S. and Forti, L. and Cesana, E. and Mapelli, J. and De Schutter, E. and D'Angelo, E.},
   title = {Fast-reset of pacemaking and theta-frequency resonance patterns in cerebellar {G}olgi cells: simulations of their impact in vivo.},
   journal = {Frontiers in Cellular Neuroscience},
   volume = {1},
   pages = {4},
   year = {2007}
}

@article{Solinas10,
   author = {Solinas, S. and Nieus, T. and D'Angelo, E.},
   title = {A realistic large-scale model of the cerebellum granular layer predicts circuit spatio-temporal filtering properties.},
   journal = {Frontiers in Cellular Neuroscience},
   volume = {4},
   pages = {12},
      year = {2010}
}

@article{Vervaeke10,
   author = {Vervaeke, K. and L\H{o}rincz, A. and Gleeson, P. and Farinella, M. and Nusser, Z. and Silver, R. A.},
   title = {Rapid desynchronization of an electrically coupled interneuron network with sparse excitatory synaptic input.},
   journal = {Neuron},
   volume = {67},
   number = {3},
   pages = {435-51},
   year = {2010}
}



@article{TopographicaPy,
   author = {Bednar, J. A.},
   title = {Topographica: Building and Analyzing Map-Level Simulations from {P}ython, {C}/{C}++, {MATLAB}, {NEST}, or {NEURON} Components.},
   journal = {Frontiers in Neuroinformatics},
   volume = {3},
   pages = {8},
   abstract = {Many neural regions are arranged into two-dimensional topographic maps, such as the retinotopic maps in mammalian visual cortex. Computational simulations have led to valuable insights about how cortical topography develops and functions, but further progress has been hindered by the lack of appropriate tools. It has been particularly difficult to bridge across levels of detail, because simulators are typically geared to a specific level, while interfacing between simulators has been a major technical challenge. In this paper, we show that the Python-based Topographica simulator makes it straightforward to build systems that cross levels of analysis, as well as providing a common framework for evaluating and comparing models implemented in other simulators. These results rely on the general-purpose abstractions around which Topographica is designed, along with the Python interfaces becoming available for many simulators. In particular, we present a detailed, general-purpose example of how to wrap an external spiking PyNN/NEST simulation as a Topographica component using only a dozen lines of Python code, making it possible to use any of the extensive input presentation, analysis, and plotting tools of Topographica. Additional examples show how to interface easily with models in other types of simulators. Researchers simulating topographic maps externally should consider using Topographica's analysis tools (such as preference map, receptive field, or tuning curve measurement) to compare results consistently, and for connecting models at different levels. This seamless interoperability will help neuroscientists and computational scientists to work together to understand how neurons in topographic maps organize and operate.},
   year = {2009}
}

@article{DavisonPy,
   author = {Davison, A. P. and Hines, M. L. and Muller, E.},
   title = {Trends in programming languages for neuroscience simulations.},
   journal = {Frontiers in Neuroscience},
   volume = {3},
   number = {3},
   pages = {374-80},
   abstract = {Neuroscience simulators allow scientists to express models in terms of biological concepts, without having to concern themselves with low-level computational details of their implementation. The expressiveness, power and ease-of-use of the simulator interface is critical in efficiently and accurately translating ideas into a working simulation. We review long-term trends in the development of programmable simulator interfaces, and examine the benefits of moving from proprietary, domain-specific languages to modern dynamic general-purpose languages, in particular Python, which provide neuroscientists with an interactive and expressive simulation development environment and easy access to state-of-the-art general-purpose tools for scientific computing.},
   year = {2009}
}

@article{Lavrentovich2008,
title = "A mathematical model of spontaneous calcium({II}) oscillations in astrocytes",
journal = "Journal of Theoretical Biology",
volume = "251",
number = "4",
pages = "553-560",
year = "2008",
note = "",
issn = "0022-5193",
author = "Maxim Lavrentovich and Sheryl Hemkin",
keywords = "Spontaneous activity",
keywords = "Glia",
keywords = "Inositol 1, 4, 5-trisphosphate",
keywords = "Astrocyte-neuron communication",
keywords = "Epilepsy"
}



@article{Kotaleski2010,
   author = {Kotaleski, J. H. and Blackwell, K. T.},
   title = {Modelling the molecular mechanisms of synaptic plasticity using systems biology approaches.},
   journal = {Nature Reviews Neuroscience},
   volume = {11},
   number = {4},
   pages = {239-51},
   abstract = {Synaptic plasticity is thought to underlie learning and memory, but the complexity of the interactions between the ion channels, enzymes and genes that are involved in synaptic plasticity impedes a deep understanding of this phenomenon. Computer modelling has been used to investigate the information processing that is performed by the signalling pathways involved in synaptic plasticity in principal neurons of the hippocampus, striatum and cerebellum. In the past few years, new software developments that combine computational neuroscience techniques with systems biology techniques have allowed large-scale, kinetic models of the molecular mechanisms underlying long-term potentiation and long-term depression. We highlight important advancements produced by these quantitative modelling efforts and introduce promising approaches that use advancements in live-cell imaging.},
   keywords = {Animals
Calcium
Computational Biology
Humans
Long-Term Potentiation
Long-Term Synaptic Depression
Models, Neurological
Neuronal Plasticity
Neurosciences
Signal Transduction
Synapses
Systems Biology},
   year = {2010}
}

@article{MUSIC,
   author = {Djurfeldt, M. and Hjorth, J. and Eppler, J. M. and Dudani, N. and Helias, M. and Potjans, T. C. and Bhalla, U. S. and Diesmann, M. and Kotaleski, J. H. and Ekeberg, O.},
   title = {Run-time interoperability between neuronal network simulators based on the {MUSIC} framework.},
   journal = {Neuroinformatics},
   volume = {8},
   number = {1},
   pages = {43-60},
   abstract = {MUSIC is a standard API allowing large scale neuron simulators to exchange data within a parallel computer during runtime. A pilot implementation of this API has been released as open source. We provide experiences from the implementation of MUSIC interfaces for two neuronal network simulators of different kinds, NEST and MOOSE. A multi-simulation of a cortico-striatal network model involving both simulators is performed, demonstrating how MUSIC can promote inter-operability between models written for different simulators and how these can be re-used to build a larger model system. Benchmarks show that the MUSIC pilot implementation provides efficient data transfer in a cluster computer with good scaling. We conclude that MUSIC fulfills the design goal that it should be simple to adapt existing simulators to use MUSIC. In addition, since the MUSIC API enforces independence of the applications, the multi-simulation could be built from pluggable component modules without adaptation of the components to each other in terms of simulation time-step or topology of connections between the modules.},
   keywords = {Action Potentials
Animals
Cerebral Cortex
Computer Simulation
Corpus Striatum
Humans
Models, Neurological
Neural Networks (Computer)
Neural Pathways
Neurons
Software
User-Computer Interface},
   year = {2010}
}

@article{Brainlab,
   author = {Drewes, R. and Zou, Q. and Goodman, P. H.},
   title = {Brainlab: A {P}ython Toolkit to Aid in the Design, Simulation, and Analysis of Spiking Neural Networks with the {N}eo{C}ortical {S}imulator.},
   journal = {Frontiers in Neuroinformatics},
   volume = {3},
   pages = {16},
   abstract = {Neuroscience modeling experiments often involve multiple complex neural network and cell model variants, complex input stimuli and input protocols, followed by complex data analysis. Coordinating all this complexity becomes a central difficulty for the experimenter. The Python programming language, along with its extensive library packages, has emerged as a leading "glue" tool for managing all sorts of complex programmatic tasks. This paper describes a toolkit called Brainlab, written in Python, that leverages Python's strengths for the task of managing the general complexity of neuroscience modeling experiments. Brainlab was also designed to overcome the major difficulties of working with the NCS (NeoCortical Simulator) environment in particular. Brainlab is an integrated model-building, experimentation, and data analysis environment for the powerful parallel spiking neural network simulator system NCS.},
   year = {2009}
}

@article{PyNEST,
   author = {Eppler, J. M. and Helias, M. and Muller, E. and Diesmann, M. and Gewaltig, M. O.},
   title = {Py{NEST}: A Convenient Interface to the {NEST} Simulator.},
   journal = {Frontiers in Neuroinformatics},
   volume = {2},
   pages = {12},
   abstract = {The neural simulation tool NEST (http://www.nest-initiative.org) is a simulator for heterogeneous networks of point neurons or neurons with a small number of compartments. It aims at simulations of large neural systems with more than 10(4) neurons and 10(7) to 10(9) synapses. NEST is implemented in C++ and can be used on a large range of architectures from single-core laptops over multi-core desktop computers to super-computers with thousands of processor cores. Python (http://www.python.org) is a modern programming language that has recently received considerable attention in Computational Neuroscience. Python is easy to learn and has many extension modules for scientific computing (e.g. http://www.scipy.org). In this contribution we describe PyNEST, the new user interface to NEST. PyNEST combines NEST's efficient simulation kernel with the simplicity and flexibility of Python. Compared to NEST's native simulation language SLI, PyNEST makes it easier to set up simulations, generate stimuli, and analyze simulation results. We describe how PyNEST connects NEST and Python and how it is implemented. With a number of examples, we illustrate how it is used.},
   year = {2008}
}

@article{PyNEURON,
   author = {Hines, M. L. and Davison, A. P. and Muller, E.},
   title = {{NEURON} and {P}ython.},
   journal = {Frontiers in Neuroinformatics},
   volume = {3},
   pages = {1},
   abstract = {The NEURON simulation program now allows Python to be used, alone or in combination with NEURON's traditional Hoc interpreter. Adding Python to NEURON has the immediate benefit of making available a very extensive suite of analysis tools written for engineering and science. It also catalyzes NEURON software development by offering users a modern programming tool that is recognized for its flexibility and power to create and maintain complex programs. At the same time, nothing is lost because all existing models written in Hoc, including graphical user interface tools, continue to work without change and are also available within the Python context. An example of the benefits of Python availability is the use of the xml module in implementing NEURON's Import3D and CellBuild tools to read MorphML and NeuroML model specifications.},
   year = {2009}
}


@article{PCSIM,
   author = {Pecevski, D. and Natschläger, T. and Schuch, K.},
   title = {{PCSIM}: A Parallel Simulation Environment for Neural Circuits Fully Integrated with {P}ython.},
   journal = {Frontiers in Neuroinformatics},
   volume = {3},
   pages = {11},
   abstract = {The Parallel Circuit SIMulator (PCSIM) is a software package for simulation of neural circuits. It is primarily designed for distributed simulation of large scale networks of spiking point neurons. Although its computational core is written in C++, PCSIM's primary interface is implemented in the Python programming language, which is a powerful programming environment and allows the user to easily integrate the neural circuit simulator with data analysis and visualization tools to manage the full neural modeling life cycle. The main focus of this paper is to describe PCSIM's full integration into Python and the benefits thereof. In particular we will investigate how the automatically generated bidirectional interface and PCSIM's object-oriented modular framework enable the user to adopt a hybrid modeling approach: using and extending PCSIM's functionality either employing pure Python or C++ and thus combining the advantages of both worlds. Furthermore, we describe several supplementary PCSIM packages written in pure Python and tailored towards setting up and analyzing neural simulations.},
   year = {2009}
}


@article{STEPS,
   author = {Wils, S. and De Schutter, E.},
   title = {{STEPS}: Modeling and Simulating Complex Reaction-Diffusion Systems with {P}ython.},
   journal = {Frontiers in Neuroinformatics},
   volume = {3},
   pages = {15},
   abstract = {We describe how the use of the Python language improved the user interface of the program STEPS. STEPS is a simulation platform for modeling and stochastic simulation of coupled reaction-diffusion systems with complex 3-dimensional boundary conditions. Setting up such models is a complicated process that consists of many phases. Initial versions of STEPS relied on a static input format that did not cleanly separate these phases, limiting modelers in how they could control the simulation and becoming increasingly complex as new features and new simulation algorithms were added. We solved all of these problems by tightly integrating STEPS with Python, using SWIG to expose our existing simulation code.},
   year = {2009}
}

@article{HodgkinHuxley1952,
    author = {Hodgkin, A. L. and Huxley, A. F.}, 
    title = {A quantitative description of membrane current and its application to conduction and excitation in nerve}, 
    volume = {117}, 
    number = {4}, 
    pages = {500-544}, 
    year = {1952}, 
    journal = {The Journal of Physiology} 
}

@incollection{CompSimEnvs,
   author = {Gleeson, Padraig and Silver, R. Angus and Steuber, Volker},
   affiliation = {University College London Department of Neuroscience, Physiology and Pharmacology London UK},
   title = {Computer {S}imulation {E}nvironments},
   booktitle = {Hippocampal Microcircuits},
   series = {Springer Series in Computational Neuroscience},
   editor = {Cutsuridis, Vassilis and Graham, Bruce and Cobb, Stuart and Vida, Imre},
   publisher = {Springer New York},
   isbn = {978-1-4419-0996-1},
   keyword = {Biomedicine},
   pages = {593-609},
   volume = {5},
   year = {2010}
}

@incollection{Gleeson2008,
title = "Using neuro{C}onstruct to Develop and Modify Biologically Detailed 3{D} Neuronal Network Models in Health and Disease",
editor = "Ivan Soltesz and Kevin Staley",
booktitle = "Computational Neuroscience in Epilepsy",
publisher = "Academic Press",
edition = "",
address = "San Diego",
year = "2008",
pages = "48-70",
isbn = "978-0-12-373649-9",
author = "Padraig Gleeson and Volker Steuber and R. Angus Silver"
}


@incollection{Graham2002,
author = "Lyle J Graham",
year = "2002",
title = "Modelling Neuronal Biophysics",
booktitle = "Handbook of Brain Theory and Neural Networks",
edition = "2nd", 
editor = "MA Arbib",
publisher = "MIT Press", 
address = "Cambridge, Massachusetts"
}

@incollection{Gleb2011,
   author = {Gleb Basalyga and Pablo M. Gleiser and Thomas Wennekers},
   title = {Emergence of small-world structure in networks of spiking neurons through {STDP} plasticity},
   booktitle = {From Brains to Systems},
   series = {Advances in Experimental Medicine and Biology},
   editor = {Hernandez, C. and Sanz, R. and Gomez-Ramirez, J. and Smith, L.S. and Hussain, A. and Chella, A. and Aleksander, I.},
   publisher = {Springer New York},
   isbn = {978-1-4614-0163-6},
   year = {2011}
}




@article{LapicqueRev,
   author = {Brunel, Nicolas and van Rossum, Mark},
   affiliation = {Universite Paris Descartes, CNRS UMR 8119 Laboratory of Neurophysics and Physiology 45 rue des Saints Peres 75270 Paris Cedex 06 France},
   title = {Lapicque's 1907 paper: {F}rom frogs to integrate-and-fire},
   journal = {Biological Cybernetics},
   publisher = {Springer Berlin / Heidelberg},
   issn = {0340-1200},
   keyword = {Computer Science},
   pages = {337-339},
   volume = {97},
   issue = {5},
   year = {2007}
}

@article{McCullochPitts,
   author = {McCulloch, Warren and Pitts, Walter},
   affiliation = {University of Illinois College of Medicine, Department of Psychiatry at the Illinois Neuropsychiatric Institute Illinois USA Illinois USA},
   title = {A logical calculus of the ideas immanent in nervous activity},
   journal = {Bulletin of Mathematical Biology},
   publisher = {Springer New York},
   issn = {0092-8240},
   keyword = {Mathematics and Statistics},
   pages = {115-133},
   volume = {5},
   issue = {4},
   year = {1943}
}

@ARTICLE{Izhikevich03,
author={Izhikevich, E.M.},
journal={Neural Networks, IEEE Transactions on}, title={Simple model of spiking neurons},
year={2003},
month={nov.},
volume={14},
number={6},
pages={ 1569-1572},
keywords={ Hodgkin-Huxley-type dynamics; biologically plausibility; bursting neurons; cortical neurons; quadratic integrate-and-fire neurons; spiking neurons; thalamus; brain models; neural nets; neurophysiology;},
ISSN={1045-9227},}


@article{Seyfarth06,
   author = {Seyfarth, Ernst-August},
   affiliation = {J.W. Goethe-Universitat Zoologisches Institut Biologie-Campus Siesmayerstrasse 70 D-60054 Frankfurt am Main Germany},
   title = {Julius {B}ernstein (1839-1917): pioneer neurobiologist and biophysicist},
   journal = {Biological Cybernetics},
   publisher = {Springer Berlin / Heidelberg},
   issn = {0340-1200},
   keyword = {Computer Science},
   pages = {2-8},
   volume = {94},
   issue = {1},
   year = {2006}
}


@book{Hille,
author = {Hille, Bertil},
title = {Ionic channels of excitable membranes},
publisher = {Sinauer Associates},
address = {Sunderland, Mass.},
edition = {3nd ed.},
year = {2001}
}

@article{Noble2002,
author = {Noble, Denis}, 
title = {Modeling the Heart: from Genes to Cells to the Whole Organ}, 
volume = {295}, 
number = {5560}, 
pages = {1678-1682}, 
year = {2002}, 
journal = {Science} 
}

@article{Herz2006,
author = {Herz, Andreas V. M. and Gollisch, Tim and Machens, Christian K. and Jaeger, Dieter}, 
title = {Modeling Single-Neuron Dynamics and Computations: A Balance of Detail and Abstraction}, 
volume = {314}, 
number = {5796}, 
pages = {80-85}, 
year = {2006}, 
abstract ={The fundamental building block of every nervous system is the single neuron. Understanding how these exquisitely structured elements operate is an integral part of the quest to solve the mysteries of the brain. Quantitative mathematical models have proved to be an indispensable tool in pursuing this goal. We review recent advances and examine how single-cell models on five levels of complexity, from black-box approaches to detailed compartmental simulations, address key questions about neural dynamics and signal processing.}, 
journal = {Science} 
}

@book{ShepherdSynaptic,
  title={The synaptic organization of the brain},
  author={Shepherd, G.M.},
  isbn={9780195159561},
  lccn={20342914},
  year={2004},
  publisher={Oxford University Press}
}

@book{gerstner2002spiking,
  title={Spiking neuron models: single neurons, populations, plasticity},
  author={Gerstner, W. and Kistler, W.M.},
  isbn={9780521890793},
  lccn={2002067657},
  year={2002},
  publisher={Cambridge University Press}
}

@article{BretteAdEx,
author = {Brette, Romain and Gerstner, Wulfram}, 
title = {Adaptive Exponential Integrate-and-Fire Model as an Effective Description of Neuronal Activity}, 
volume = {94}, 
number = {5}, 
pages = {3637-3642}, 
year = {2005}, 
journal = {Journal of Neurophysiology} 
}

@article{FitzHugh1961,
title = "Impulses and Physiological States in Theoretical Models of Nerve Membrane",
journal = "Biophysical Journal",
volume = "1",
number = "6",
pages = "445-466",
year = "1961",
issn = "0006-3495",
author = "Richard FitzHugh"
}

@article{Blackwell2006,
title = "An efficient stochastic diffusion algorithm for modeling second messengers in dendrites and spines",
journal = "Journal of Neuroscience Methods",
volume = "157",
number = "1",
pages = "142-153",
year = "2006",
issn = "0165-0270",
author = "Kim T. Blackwell",
keywords = "Diffusion",
keywords = "Stochastic",
keywords = "Second messenger",
keywords = "Computer software"
}

@article{Coggan2005,
author = {Coggan, Jay S. and Bartol, Thomas M. and Esquenazi, Eduardo and Stiles, Joel R. and Lamont, Stephan and Martone, Maryann E. and Berg, Darwin K. and Ellisman, Mark H. and Sejnowski, Terrence J.}, 
title = {Evidence for Ectopic Neurotransmission at a Neuronal Synapse}, 
volume = {309}, 
number = {5733}, 
pages = {446-451}, 
year = {2005}, 
abstract ={Neurotransmitter release is well known to occur at specialized synaptic regions that include presynaptic active zones and postsynaptic densities. At cholinergic synapses in the chick ciliary ganglion, however, membrane formations and physiological measurements suggest that release distant from postsynaptic densities can activate the predominantly extrasynaptic α7 nicotinic receptor subtype. We explored such ectopic neurotransmission with a novel model synapse that combines Monte Carlo simulations with high-resolution serial electron microscopic tomography. Simulated synaptic activity is consistent with experimental recordings of miniature excitatory postsynaptic currents only when ectopic transmission is included in the model, broadening the possibilities for mechanisms of neuronal communication.}, 
journal = {Science} 
}


@incollection{GurneyCSN,
   author = { Gurney, Kevin and  Humphries, Mark},
   title = {Methodological issues in modelling at multiple levels of description},
   booktitle = {Computational Systems Neurobiology},
   editor = {Le Nov\`{e}re, Nicolas and Bhalla, Upinder S},
   publisher = {Springer},
   year = {in press}
}
@incollection{LansnerDiesmann,
   author = {Anders Lansner and Markus Diesmann},
   title = {Virtues, pitfalls, and methodology related to large-scale neuronal network models and supercomputer simulations},
   booktitle = {Computational Systems Neurobiology},
   editor = {Le Nov\`{e}re, Nicolas and Bhalla, Upinder S},
   publisher = {Springer},
   year = {in press}
}

@incollection{GleesonNeuroML2011,
   author = {Padraig Gleeson and Volker Steuber and R. Angus Silver and Sharon Crook},
   title = {Neuro{ML}},
   booktitle = {Computational Systems Neurobiology},
   editor = {Le Nov\`{e}re, Nicolas and Bhalla, Upinder S},
   publisher = {Springer},
   year = {in press}
}

@article{BeanAP,
author = {Bean, B. P.},
title = {The action potential in mammalian central neurons},
journal = {Nature Reviews Neuroscience},
volume = {8},
number = {6},
pages = {451-65},
year = {2007}
}

@article{Stuart1997,
title = "Action potential initiation and backpropagation in neurons of the mammalian {CNS}",
journal = "Trends in Neurosciences",
volume = "20",
number = "3",
pages = "125-131",
year = "1997",
author = "Greg Stuart and Nelson Spruston and Bert Sakmann and Michael H{\"a}usser",
keywords = "dendrites",
keywords = "central nervous system",
keywords = "active propogation",
keywords = "sodium channels",
keywords = "synaptic integration",
keywords = "neurons"
}


@article{vanOoyen2002,
author = {van Ooyen, Arjen and Duijnhouwer, Jacob and Remme, Michiel W H and van Pelt, Jaap},
title = {The effect of dendritic topology on firing patterns in model neurons},
journal = {Network: Computation in Neural Systems},
volume = {13},
number = {3},
pages = {311-325},
year = {2002}
}

@article{MainenSejnowski1996,
author = {Mainen, Z. F. and Sejnowski, T. J.},
title = {Influence of dendritic structure on firing pattern in model neocortical neurons.},
journal = {Nature},
volume = {382},
number = {6589},
pages = {363-6},
year = {1996}
}

@article{Klausberger2008,
author = {Klausberger, Thomas and Somogyi, Peter}, 
title = {Neuronal Diversity and Temporal Dynamics: The Unity of Hippocampal Circuit Operations}, 
volume = {321}, 
number = {5885}, 
pages = {53-57}, 
year = {2008}, 
journal = {Science} 
}

@article{Silver2003,
author = {Silver, R. Angus and L\"{u}bke, Joachim and Sakmann, Bert and Feldmeyer, Dirk}, 
title = {High-Probability Uniquantal Transmission at Excitatory Synapses in Barrel Cortex}, 
volume = {302}, 
number = {5652}, 
pages = {1981-1984}, 
year = {2003}, 
abstract ={The number of vesicles released at excitatory synapses and the number of release sites per synaptic connection are key determinants of information processing in the cortex, yet they remain uncertain. Here we show that the number of functional release sites and the number of anatomically identified synaptic contacts are equal at connections between spiny stellate and pyramidal cells in rat barrel cortex. Moreover, our results indicate that the amount of transmitter released per synaptic contact is independent of release probability and the intrinsic release probability is high. These properties suggest that connections between layer 4and layer 2/3 are tuned for reliable transmission of spatially distributed, timing-based signals.}, 
journal = {Science} 
}

@article{Lefort2009,
title = "The Excitatory Neuronal Network of the {C}2 Barrel Column in Mouse Primary Somatosensory Cortex",
journal = "Neuron",
volume = "61",
number = "2",
pages = "301-316",
year = "2009",
author = "Sandrine Lefort and Christian Tomm and J.-C. Floyd Sarria and Carl C.H. Petersen",
keywords = "SYSNEURO"
}

@article{Petersen2007,
title = "The Functional Organization of the Barrel Cortex",
journal = "Neuron",
volume = "56",
number = "2",
pages = "339-355",
year = "2007",
author = "Carl C.H. Petersen"
}

@article{Rancz2011,
   author = {Rancz, E. A. and Franks, K. M. and Schwarz, M. K. and Pichler, B. and Schaefer, A. T. and Margrie, T. W.},
   title = {Transfection via whole-cell recording in vivo: bridging single-cell physiology, genetics and connectomics.},
   journal = {Nat Neurosci},
   volume = {14},
   number = {4},
   pages = {527-32},
   abstract = {Single-cell genetic manipulation is expected to substantially advance the field of systems neuroscience. However, existing gene delivery techniques do not allow researchers to electrophysiologically characterize cells and to thereby establish an experimental link between physiology and genetics for understanding neuronal function. In the mouse brain in vivo, we found that neurons remained intact after 'blind' whole-cell recording, that DNA vectors could be delivered through the patch-pipette during such recordings and that these vectors drove protein expression in recorded cells for at least 7 d. To illustrate the utility of this approach, we recorded visually evoked synaptic responses in primary visual cortical cells while delivering DNA plasmids that allowed retrograde, monosynaptic tracing of each neuron's presynaptic inputs. By providing a biophysical profile of a cell before its specific genetic perturbation, this combinatorial method captures the synaptic and anatomical receptive field of a neuron.},
   keywords = {Animals
Brain
Genetic Vectors
Mice
Mice, Inbred C57BL
Neuroanatomical Tract-Tracing Techniques
Neurons
Organ Culture Techniques
Patch-Clamp Techniques
Transfection},
   year = {2011}
}



@article{LubkeFeldmeyer2007,
   author = {L\"{u}bke, Joachim and Feldmeyer, Dirk},
   affiliation = {Institute of Neurosciences and Biophysics INB-3 Research Centre Jülich Leo-Brandt-Str 52425 Jülich Germany},
   title = {Excitatory signal flow and connectivity in a cortical column: focus on barrel cortex},
   journal = {Brain Structure and Function},
   publisher = {Springer Berlin / Heidelberg},
   issn = {1863-2653},
   keyword = {Medicine},
   pages = {3-17},
   volume = {212},
   issue = {1},
   year = {2007}
}

@article{Boyden2005,
   author = {Boyden, E. S. and Zhang, F. and Bamberg, E. and Nagel, G. and Deisseroth, K.},
   title = {Millisecond-timescale, genetically targeted optical control of neural activity.},
   journal = {Nature Neuroscience},
   volume = {8},
   number = {9},
   pages = {1263-8},
   abstract = {Temporally precise, noninvasive control of activity in well-defined neuronal populations is a long-sought goal of systems neuroscience. We adapted for this purpose the naturally occurring algal protein Channelrhodopsin-2, a rapidly gated light-sensitive cation channel, by using lentiviral gene delivery in combination with high-speed optical switching to photostimulate mammalian neurons. We demonstrate reliable, millisecond-timescale control of neuronal spiking, as well as control of excitatory and inhibitory synaptic transmission. This technology allows the use of light to alter neural processing at the level of single spikes and synaptic events, yielding a widely applicable tool for neuroscientists and biomedical engineers.},
   year = {2005}
}


@article{Briggman2006,
title = "Towards neural circuit reconstruction with volume electron microscopy techniques",
journal = "Current Opinion in Neurobiology",
volume = "16",
number = "5",
pages = "562-570",
year = "2006",
issn = "0959-4388",
author = "Kevin L Briggman and Winfried Denk"
}

@article{Douglas_Martin_2004,
title={Neuronal circuits of the neocortex.}, 
volume={27}, 
 number={1}, 
journal={Annual Review of Neuroscience}, 
publisher={Annual Reviews}, 
author={Douglas, Rodney J and Martin, Kevan A C}, 
year={2004}, 
pages={419--451}}

@ARTICLE{CX3D,
 AUTHOR={Frederic Zubler  and  Rodney Douglas},     
TITLE={A framework for modeling the growth and development of neurons and networks},      
JOURNAL={Frontiers in Computational Neuroscience},      
VOLUME={3},      
YEAR={2009},      
NUMBER={0},     
ABSTRACT={The development of neural tissue is a complex organizing process, in which it is difficult to grasp how the various localized interactions between dividing cells leads relentlessly to global network organization.  Simulation is a useful tool for exploring such complex processes because it permits rigorous analysis of  observed global behavior in terms of the mechanistic axioms declared in the simulated model.  We describe a novel simulation tool, CX3D, for modeling the development of large realistic neural networks such as the neocortex, in a physical 3D space. In CX3D, as in biology, neurons arise by the replication and migration of precursors, which mature into cells able to extend axons and dendrites. Individual neurons are discretized into spherical (for the soma) and cylindrical (for neurites) elements that have appropriate mechanical properties. The growth functions of each neuron are encapsulated in set of pre-defined modules that are automatically distributed across its segments during growth. The extracellular space is also discretized, and allows for the diffusion of extracellular signaling molecules, as well as the physical interactions of the many developing neurons.  We demonstrate the utility of CX3D by simulating three interesting developmental processes: neocortical lamination based on mechanical properties of tissues; a growth model of a neocortical pyramidal cell based on layer-specific guidance cues; and the formation of a neural network in vitro by employing neurite fasciculation. We also provide some examples in which previous models from the literature are re-implemented in CX3D. Our results suggest that CX3D is a powerful tool for understanding neural development.}}

@ARTICLE{Thomson2007,
 AUTHOR={Alex M Thomson  and  Christophe Lamy},     
TITLE={Functional maps of neocortical local circuitry},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={1},      
YEAR={2007},      
NUMBER={1}}

@article{Somogyi1998,
title = "Salient features of synaptic organisation in the cerebral cortex",
journal = "Brain Research Reviews",
volume = "26",
number = "2-3",
pages = "113-135",
year = "1998",
issn = "0165-0173",
author = "Peter Somogyi and Gabor Tamas and Rafael Lujan and Eberhard H. Buhl",
keywords = "Neocortex",
keywords = "Hippocampus",
keywords = "Glutamate receptor",
keywords = "GABA receptor",
keywords = "Synapse",
keywords = "Neurotransmission"
}

@article{Harvey1991,
title = "Quantitatives studies on the mammalian cerebellum",
journal = "Progress in Neurobiology",
volume = "36",
number = "6",
pages = "437-463",
year = "1991",
issn = "0301-0082",
author = "R.J. Harvey and R.M.A. Napper"
}

@article{Douglas2007,
title = "Mapping the Matrix: The Ways of Neocortex",
journal = "Neuron",
volume = "56",
number = "2",
pages = "226-238",
year = "2007",
issn = "0896-6273",
author = "Rodney J. Douglas and Kevan A.C. Martin"
}

@article{Vos1999,
author = {Vos, Bart P. and Maex, Reinoud and Volny-Luraghi, Antonia and Schutter, Erik De}, 
title = {Parallel Fibers Synchronize Spontaneous Activity in Cerebellar {G}olgi Cells}, 
volume = {19}, 
number = {11}, 
pages = {RC6}, 
year = {1999}, 
journal = {The Journal of Neuroscience} 
}

@article{Ko2011, 
title={Functional specificity of local synaptic connections in neocortical networks}, 
volume={473},
number={7345}, 
journal={Nature}, 
publisher={Nature Publishing Group}, 
author={Ko, Ho and Hofer, Sonja B and Pichler, Bruno and Buchanan, Katherine A and Sj\"{o}str\"{o}m, P Jesper and Mrsic-Flogel, Thomas D}, 
year={2011}, 
pages={87-91}}


@book{RallSelected,
author = {Rall, Wilfrid and Segev, Idan and Rinzel, John and Shepherd, Gordon M.},
title = {The theoretical foundation of dendritic function: selected papers of Wilfrid Rall with commentaries},
publisher = {MIT Press},
address = {Cambridge, Mass. ; London},
keywords = {Dendrites Mathematical models.},
pages = {456p.},
year = {1995}
}

@article{Dugue2009,
title = "Electrical Coupling Mediates Tunable Low-Frequency Oscillations and Resonance in the Cerebellar {G}olgi Cell Network",
journal = "Neuron",
volume = "61",
number = "1",
pages = "126-139",
year = "2009",
note = "",
author = "Guillaume P. Dugu\'{e} and Nicolas Brunel and Vincent Hakim and Eric Schwartz and Mireille Chat and Maxime L\'{e}vesque and Richard Courtemanche and Cl\'{e}ment L\'{e}na and St\'{e}phane Dieudonn\'{e}"
}



@article{Rhodes1994,
 author = {Rhodes, Paul A. and Gray, Charles M.},
 title = {Simulations of intrinsically bursting neocortical pyramidal neurons},
 journal = {Neural Computation.},
 volume = {6},
 issue = {6},
 month = {November},
 year = {1994},
 issn = {0899-7667},
 pages = {1086--1110},
 numpages = {25},
 acmid = {1362290},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@article{Izhikevich2008,
author = {Izhikevich, Eugene M. and Edelman, Gerald M.}, 
title = {Large-scale model of mammalian thalamocortical systems}, 
volume = {105}, 
number = {9}, 
pages = {3593-3598}, 
year = {2008}, 
journal = {Proceedings of the National Academy of Sciences} 
}

@ARTICLE{SPLIT2008,
author={Djurfeldt, M. and Lundqvist, M. and Johansson, C. and Rehn, M. and Ekeberg, O. and Lansner, A.},
journal={IBM Journal of Research and Development}, 
title={Brain-scale simulation of the neocortex on the {IBM} {B}lue {G}ene/{L} supercomputer},
year={2008},
volume={52},
number={1.2},
pages={31-41},
ISSN={0018-8646}
}


@incollection{EfficientNEST,
   author = {Plesser, Hans and Eppler, Jochen and Morrison, Abigail and Diesmann, Markus and Gewaltig, Marc-Oliver},
   affiliation = {Dept. of Mathematical Sciences and Technology, Norwegian University of Life Sciences, PO Box 5003, 1432 Ås Norway},
   title = {Efficient Parallel Simulation of Large-Scale Neuronal Networks on Clusters of Multiprocessor Computers},
   booktitle = {Euro-Par 2007 Parallel Processing},
   series = {Lecture Notes in Computer Science},
   editor = {Kermarrec, Anne-Marie and Bougé, Luc and Priol, Thierry},
   publisher = {Springer Berlin / Heidelberg},
   pages = {672-681},
   volume = {4641},
   year = {2007}
}


@article{Goodman2010,
   author = {Goodman, Dan},
   affiliation = {Laboratoire Psychologie de la Perception, CNRS, Université Paris Descartes, Paris, France},
   title = {Code Generation: {A} Strategy for Neural Network Simulators},
   journal = {Neuroinformatics},
   publisher = {Humana Press Inc.},
   issn = {1539-2791},
   keyword = {Biomedical and Life Sciences},
   pages = {183-196},
   volume = {8},
   issue = {3},
   year = {2010}
}

@article{Golowasch2002,
author = {Golowasch, Jorge and Goldman, Mark S. and Abbott, L. F. and Marder, Eve}, 
title = {Failure of Averaging in the Construction of a Conductance-Based Neuron Model}, 
volume = {87}, 
number = {2}, 
pages = {1129-1131}, 
year = {2002}, 
abstract ={Parameters for models of biological systems are often obtained by averaging over experimental results from a number of different preparations. To explore the validity of this procedure, we studied the behavior of a conductance-based model neuron with five voltage-dependent conductances. We randomly varied the maximal conductance of each of the active currents in the model and identified sets of maximal conductances that generate bursting neurons that fire a single action potential at the peak of a slow membrane potential depolarization. A model constructed using the means of the maximal conductances of this population is not itself a one-spike burster, but rather fires three action potentials per burst. Averaging fails because the maximal conductances of the population of one-spike bursters lie in a highly concave region of parameter space that does not contain its mean. This demonstrates that averages over multiple samples can fail to characterize a system whose behavior depends on interactions involving a number of highly variable components.}, 
journal = {Journal of Neurophysiology} 
}

@INPROCEEDINGS{fidjeland10nemo,
  author = {A. K. Fidjeland and M. P. Shanahan},
  title = {Accelerated Simulation of Spiking Neural Networks Using {GPU}s},
  year = {2010},
  month = {July},
  booktitle = {Proc. IEEE International Joint Conference on Neural Networks}
}


@article{Kitano2002,
author = {Kitano, Hiroaki}, 
title = {Systems Biology: {A} Brief Overview}, 
volume = {295}, 
number = {5560}, 
pages = {1662-1664}, 
year = {2002}, 
abstract ={To understand biology at the system level, we must examine the structure and dynamics of cellular and organismal function, rather than the characteristics of isolated parts of a cell or organism. Properties of systems, such as robustness, emerge as central issues, and understanding these properties may have an impact on the future of medicine. However, many breakthroughs in experimental devices, advanced software, and analytical methods are required before the achievements of systems biology can live up to their much-touted potential.}, 
journal = {Science} 
}

@article{Schilstra2006,
author = {Schilstra, Maria J. and Li, Lu and Matthews, Joanne and Finney, Andrew and Hucka, Michael and Le Novère, Nicolas}, 
title = {Cell{ML}2{SBML}: conversion of {C}ell{ML} into {SBML}}, 
volume = {22}, 
number = {8}, 
pages = {1018-1020}, 
year = {2006}, 
abstract ={Summary: CellML and SBML are XML-based languages for storage and exchange of molecular biological and physiological reaction models. They use very similar subsets of MathML to specify the mathematical aspects of the models. CellML2SBML is implemented as a suite of XSLT stylesheets that, when applied consecutively, convert models expressed in CellML into SBML without significant loss of information. The converter is based on the most recent stable versions of the languages (CellML version 1.1; SBML Level 2 Version 1), and the XSLT used in the stylesheets adheres to the XSLT version 1.0 specification. Of all 306 models in the CellML repository in April 2005, CellML2SBML converted 91% automatically into SBML. Minor manual changes to the unit definitions in the originals raised the percentage of successful conversions to 96%.Availability:http://sbml.org/software/cellml2sbml/Contact:m.j.1.schilstra@herts.ac.ukSupplementary information: Instructions for use and further documentation available on http://sbml.org/software/cellml2sbml/}, 
journal = {Bioinformatics} 
}

@Article{KohlNobleVPH,
author = "Kohl, P and Noble, D",
title = {Systems {B}iology and the {V}irtual {P}hysiological {H}uman},
abstract = {},
journal = "Molecular Systems Biology",
year = "2009",
volume = "5",
number = "292",
pages = "1-6",
pmid = "19638973"
}

@article{Rothman2009,
   author = {Rothman, J. S. and Cathala, L. and Steuber, V. and Silver, R. A.},
   title = {Synaptic depression enables neuronal gain control.},
   journal = {Nature},
   volume = {457},
   number = {7232},
   pages = {1015-8},
   abstract = {To act as computational devices, neurons must perform mathematical operations as they transform synaptic and modulatory input into output firing rate. Experiments and theory indicate that neuronal firing typically represents the sum of synaptic inputs, an additive operation, but multiplication of inputs is essential for many computations. Multiplication by a constant produces a change in the slope, or gain, of the input-output relationship, amplifying or scaling down the sensitivity of the neuron to changes in its input. Such gain modulation occurs in vivo, during contrast invariance of orientation tuning, attentional scaling, translation-invariant object recognition, auditory processing and coordinate transformations. Moreover, theoretical studies highlight the necessity of gain modulation in several of these tasks. Although potential cellular mechanisms for gain modulation have been identified, they often rely on membrane noise and require restrictive conditions to work. Because nonlinear components are used to scale signals in electronics, we examined whether synaptic nonlinearities are involved in neuronal gain modulation. We used synaptic stimulation and the dynamic-clamp technique to investigate gain modulation in granule cells in acute slices of rat cerebellum. Here we show that when excitation is mediated by synapses with short-term depression (STD), neuronal gain is controlled by an inhibitory conductance in a noise-independent manner, allowing driving and modulatory inputs to be multiplied together. The nonlinearity introduced by STD transforms inhibition-mediated additive shifts in the input-output relationship into multiplicative gain changes. When granule cells were driven with bursts of high-frequency mossy fibre input, as observed in vivo, larger inhibition-mediated gain changes were observed, as expected with greater STD. Simulations of synaptic integration in more complex neocortical neurons suggest that STD-based gain modulation can also operate in neurons with large dendritic trees. Our results establish that neurons receiving depressing excitatory inputs can act as powerful multiplicative devices even when integration of postsynaptic conductances is linear.},
   keywords = {Animals
Dendrites
Excitatory Postsynaptic Potentials
Long-Term Synaptic Depression
Models, Neurological
Neocortex
Nerve Fibers
Neurons
Pyramidal Cells
Rats
Rats, Sprague-Dawley
Receptors, AMPA
Receptors, N-Methyl-D-Aspartate
Synapses},
   year = {2009}
}


@conference{FarinellaL5,
author = "Matteo Farinella and Padraig Gleeson and Daniel  Ruedt and Angus Silver",
title = {Synaptic integration and {NMDA} spikes in a layer 5 pyramidal neuron model},
booktitle = "Proceedings of the Twentieth Annual Computational Neuroscience Meeting, CNS*2011",
year = "2011"
}

@book{Marr1982,
author = {Marr, David},
title = {Vision: a computational investigation into the human representation and processing of visual information},
publisher = {Freeman},
address = {New York},
pages = {397 p.},
year = {1982}
}

@article{Marr1977, 
title={From Understanding Computation to Understanding Neural Circuitry}, 
volume={15}, 
journal={Neurosciences Research Program Bulletin}, 
author={Marr, David and Poggio, Tomaso}, 
year={1977}, 
pages={470-488}
}


@article{Maex1998,
author = {Maex, Reinoud and Schutter, Erik De}, 
title = {Synchronization of {G}olgi and Granule Cell Firing in a Detailed Network Model of the Cerebellar Granule Cell Layer}, 
volume = {80}, 
number = {5}, 
pages = {2521-2537}, 
year = {1998}, 
abstract ={
Maex, Reinoud and Erik De Schutter. Synchronization of Golgi and granule cell firing in a detailed network model of the cerebellar granule cell layer. J. Neurophysiol. 80: 2521–2537, 1998. The granular layer of the cerebellum has a disproportionately large number of excitatory (granule cells) versus inhibitory neurons (Golgi cells). Its synaptic organization is also unique with a dense reciprocal innervation between granule and Golgi cells but without synaptic contacts among the neurons of either population. Physiological recordings of granule or Golgi cell activity are scarce, and our current thinking about the way the granular layer functions is based almost exclusively on theoretical considerations. We computed the steady-state activity of a large-scale model of the granular layer of the rat cerebellum. Within a few tens of milliseconds after the start of random mossy fiber input, the populations of Golgi and granule cells became entrained in a single synchronous oscillation, the basic frequency of which ranged from 10 to 40 Hz depending on the average rate of firing in the mossy fiber population. The long parallel fibers ensured, through α-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid-mediated synapses, a coherent excitation of Golgi cells, while the regular firing of each Golgi cell synchronized all granule cells within its axonal radius through transient activation of their γ-aminobutyric acid-A (GABAA) receptor synapses. Individual granule cells often remained silent during a few successive oscillation cycles so that their average firing rates, which could be quite variable, reflected the average activities of their mossy fiber afferents. The synchronous, rhythmic firing pattern was robust over a broad range of biologically realistic parameter values and to parameter randomization. Three conditions, however, made the oscillations more transient and could desynchronize the entire network in the end: a very low mossy fiber activity, a very dominant excitation of Golgi cells through mossy fiber synapses (rather than through parallel fiber synapses), and a tonic activation of granule cell GABAA receptors (with an almost complete absence of synaptically induced inhibitory postsynaptic currents). These three conditions were associated with a reduction in the parallel fiber activity, and synchrony could be restored by increasing the mossy fiber firing rate. The model predicts that, under conditions of strong mossy fiber input to the cerebellum, Golgi cells do not only control the strength of parallel fiber activity but also the timing of the individual spikes. Provided that their parallel fiber synapses constitute an important source of excitation, Golgi cells fire rhythmically and synchronized with granule cells over large distances along the parallel fiber axis. According to the model, the granular layer of the cerebellum is desynchronized when the mossy fiber firing rate is low.}, 
journal = {Journal of Neurophysiology} 
}

@article{Kole2008, 
title={Action potential generation requires a high sodium channel density in the axon initial segment.}, 
volume={11}, 
number={2}, journal={Nature Neuroscience}, 
publisher={Nature Publishing Group}, 
author={Kole, Maarten H P and Ilschner, Susanne U and Kampa, Björn M and Williams, Stephen R and Ruben, Peter C and Stuart, Greg J}, 
year={2008}, 
pages={178-186}
}

@article{Migliore2005,
author = {Migliore, Michele and Ferrante, Michele and Ascoli, Giorgio A.}, 
title = {Signal Propagation in Oblique Dendrites of {CA}1 Pyramidal Cells}, 
volume = {94}, 
number = {6}, 
pages = {4145-4155}, 
year = {2005}, 
abstract ={
         The electrophysiological properties of the oblique branches of CA1 pyramidal neurons are largely unknown and very difficult
         to investigate experimentally. These relatively thin dendrites make up the majority of the apical tree surface area and constitute
         the main target of Schaffer collateral axons from CA3. Their electrogenic properties might have an important role in defining
         the computational functions of CA1 neurons. It is thus important to determine if and to what extent the back- and forward
         propagation of action potentials (AP) in these dendrites could be modulated by local properties such as morphology or active
         conductances. In the first detailed study of signal propagation in the full extent of CA1 oblique dendrites, we used 27 reconstructed
         three-dimensional morphologies and different distributions of the A-type K+ conductance (KA), to investigate their electrophysiological properties by computational modeling. We found that the local KA distribution had a major role in modulating action potential back propagation, whereas the forward propagation of dendritic
         spikes originating in the obliques was mainly affected by local morphological properties. In both cases, signal processing
         in any given oblique was effectively independent of the rest of the neuron and, by and large, of the distance from the soma.
         Moreover, the density of KA in oblique dendrites affected spike conduction in the main shaft. Thus the anatomical variability of CA1 pyramidal cells
         and their local distribution of voltage-gated channels may suit a powerful functional compartmentalization of the apical tree.
         
      }, 
journal = {Journal of Neurophysiology} 
}

@article{Berends2005,
author = {Berends, Michiel and Maex, Reinoud and Schutter, Erik De},
title = {The Effect of {NMDA} Receptors on Gain Modulation},
journal = {Neural Computationation},
volume = {17},
number = {12},
pages = {2531-2547},
year = {2005}
}

@article{Cunningham2004,
author = {Cunningham, Mark O. and Whittington, Miles A. and Bibbig, Andrea and Roopun, Anita and LeBeau, Fiona E. N. and Vogt, Angelika and Monyer, Hannah and Buhl, Eberhard H. and Traub, Roger D.}, 
title = {A role for fast rhythmic bursting neurons in cortical gamma oscillations in vitro}, 
volume = {101}, 
number = {18}, 
pages = {7152-7157}, 
year = {2004}, 
abstract ={Basic cellular and network mechanisms underlying gamma frequency oscillations (30–80 Hz) have been well characterized in the hippocampus and associated structures. In these regions, gamma rhythms are seen as an emergent property of networks of principal cells and fast-spiking interneurons. In contrast, in the neocortex a number of elegant studies have shown that specific types of principal neuron exist that are capable of generating powerful gamma frequency outputs on the basis of their intrinsic conductances alone. These fast rhythmic bursting (FRB) neurons (sometimes referred to as “chattering” cells) are activated by sensory stimuli and generate multiple action potentials per gamma period. Here, we demonstrate that FRB neurons may function by providing a large-scale input to an axon plexus consisting of gap-junctionally connected axons from both FRB neurons and their anatomically similar counterparts regular spiking neurons. The resulting network gamma oscillation shares all of the properties of gamma oscillations generated in the hippocampus but with the additional critical dependence on multiple spiking in FRB cells.}, 
journal = {Proceedings of the National Academy of Sciences} 
}

@article{Albus1971,
title = "A theory of cerebellar function",
journal = "Mathematical Biosciences",
volume = "10",
number = "1-2",
pages = "25-61",
year = "1971",
issn = "0025-5564",
author = "James S. Albus"
}


@ARTICLE{Marr1969,
author={Marr, David},
title={A theory of cerebellar cortex.},
journal={Journal of Physiology},
year={1969},
volume={202},
number={2},
pages={437-470},
document_type={Article}
}


@article{Tyrrell1992,
author = {Tyrrell, Toby and Willshaw, David}, 
title = {Cerebellar Cortex: Its Simulation and the Relevance of {M}arr's Theory}, 
volume = {336}, 
number = {1277}, 
pages = {239-257}, 
year = {1992}, 
abstract ={Marr's theory of the cerebellar cortex as an associative learning device is one of the best examples of a theory that directly relates the function of a neural system to its neural structure. However, although he assigned a precise function to each of the identified cell types of the cerebellar cortex, many of the crucial aspects of the implementation of his theory remained unspecified. We attempted to resolve these difficulties by constructing a computer simulation which contained a direct representation of the 13 000 mossy fibres and the 200 000 granule cells associated with a single Purkinje cell of the cerebellar cortex, together with the supporting Golgi, basket and stellate cells. In this paper we present a detailed explanation of Marr's theory based upon an analogy between Marr's cerebellar model and an abstract model called the associative net. Although some of Marr's assumptions contravene neuroanatomical findings, we found that in general terms his conclusion that each Purkinje cell can learn to respond to a large number of different patterns of activity in the mossy fibres is substantially correct. However, we found that this system has a lower capacity and acts more stochastically than he envisaged. The biologically realistic simulated structure that we designed can be used to assess the computational capabilities of other network theories of the cerebellum.}, 
journal = {Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences} 
}


@article{Stanley2011,
   author = {Stanley, David and Bardakjian, Berj and Spano, Mark and Ditto, William},
   affiliation = {School of Biological and Health Systems Engineering, Arizona State University, Tempe, AZ 85287, USA},
   title = {Stochastic amplification of calcium-activated potassium currents in {C}a\supers{2+} microdomains},
   journal = {Journal of Computational Neuroscience},
   publisher = {Springer Netherlands},
   issn = {0929-5313},
   keyword = {Computer Science},
   pages = {1-20},
   year = {2011}
}

@article{Gouwens2009,
author = {Gouwens, Nathan W. and Wilson, Rachel I.}, 
title = {Signal Propagation in Drosophila Central Neurons}, 
volume = {29}, 
number = {19}, 
pages = {6239-6249}, 
year = {2009}, 
abstract ={Drosophila is an important model organism for investigating neural development, neural morphology, neurophysiology, and neural correlates of behaviors. However, almost nothing is known about how electrical signals propagate in Drosophila neurons. Here, we address these issues in antennal lobe projection neurons, one of the most well studied classes of Drosophila neurons. We use morphological and electrophysiological data to deduce the passive membrane properties of these neurons and to build a compartmental model of their electrotonic structure. We find that these neurons are electrotonically extensive and that a somatic recording electrode can only imperfectly control the voltage in the rest of the cell. Simulations predict that action potentials initiate at a location distant from the soma, in the proximal portion of the axon. Simulated synaptic input to a single dendritic branch propagates poorly to the rest of the cell and cannot match the size of real unitary synaptic events, but we can obtain a good fit to data when we model unitary input synapses as dozens of release sites distributed across many dendritic branches. We also show that the true resting potential of these neurons is more hyperpolarized than previously thought, attributable to the experimental error introduced by the electrode seal conductance. A leak sodium conductance also contributes to the resting potential. Together, these findings have fundamental implications for how these neurons integrate their synaptic inputs. Our results also have important consequences for the design and interpretation of experiments aimed at understanding Drosophila neurons and neural circuits.}, 
journal = {The Journal of Neuroscience} 
}



@article{Kirkby2010, 
author = {Paul A. Kirkby and K. M. Naga Srinivas Nadella and R. Angus Silver}, 
journal = {Optics Express}, 
keywords = {Fluorescence microscopy; Three-dimensional microscopy; Acousto-optical devices; Femtosecond phenomena},
number = {13}, 
pages = {13720--13744}, 
publisher = {OSA},
title = {A compact acousto-optic lens for 2{D} and 3{D} femtosecond based 2-photon microscopy}, 
volume = {18}, 
month = {Jun},
year = {2010},
abstract = {We describe a high speed 3D Acousto-Optic Lens Microscope (AOLM) for femtosecond 2-photon imaging. By optimizing the design of the 4 AO Deflectors (AODs) and by deriving new control algorithms, we have developed a compact spherical AOL with a low temporal dispersion that enables 2-photon imaging at 10-fold lower power than previously reported. We show that the AOLM can perform high speed 2D raster-scan imaging (\&gt;150 Hz) without scan rate dependent astigmatism. It can deflect and focus a laser beam in a 3D random access sequence at 30 kHz and has an extended focusing range (\&gt;137 $\mu$m; 40X 0.8NA objective). These features are likely to make the AOLM a useful tool for studying fast physiological processes distributed in 3D space},
}



@book{Eccles1967,
   author = {John C. Eccles and Masao Ito and J\'{a}nos Szent\'{a}gothai},
   title = {The Cerebellum as a Neuronal Machine},
   publisher = {Springer-Verlag},
   address = {New York},
   year = {1967}
}

@book{Palay1974,
   author = {Palay, S. L. and Chan-Palay, V.},
   title = {Cerebellar Cortex: Cytology and Organization},
   publisher = {Springer-Verlag},
   address = {New York},
   year = {1974}
}

@book{Gell95,
   author = {Murray Gell-Mann},
   title = {The Quark and the Jaguar: {A}dventures in the Simple and the Complex},
   publisher = {Abacus},
   year = {1995}
}

@article{Howell2000,
title = "A large-scale model of the cerebellar cortex using {PGENESIS}",
journal = "Neurocomputing",
volume = "32-33",
number = "",
pages = "1041-1046",
year = "2000",
issn = "0925-2312",
author = "F. W. Howell and J. Dyhrfjeld-Johnsen and R. Maex and N. Goddard and E. De Schutter",
keywords = "Large-scale modelling",
keywords = "PGENESIS",
keywords = "Cerebellum"
}

@ARTICLE{Rokni2008,
AUTHOR={Dan Rokni  and  Rodolfo R Llinas  and  Yosef Yarom},     
TITLE={The morpho/functional discrepancy in the cerebellar cortex: Looks alone are deceptive.},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={2},          
YEAR={2008},          
NUMBER={0},            
ISSN={1662-453X},      
ABSTRACT={In a recent report we demonstrated that stimulation of cerebellar mossy fibers synchronously activates Purkinje cells that are located directly above the site of stimulation. We found that the activated Purkinje cells are arranged in a radial patch on the cerebellar surface and that this organization is independent of the integrity of the inhibitory system. This arrangement of activity is counterintuitive. The anatomical structure with the extensive parallel fiber system implies that mossy fiber stimulation will activate Purkinje cells along a beam of parallel fibers. In this short review we highlight this discrepancy between anatomical structure and functional dynamics and suggest a plausible underlying mechanism.}
}

@article{DAngelo2011,
title = "The cerebellar network: {F}rom structure to function and dynamics",
journal = "Brain Research Reviews",
volume = "66",
number = "1-2",
pages = "5-15",
year = "2011",
author = "E. D'Angelo and P. Mazzarello and F. Prestori and J. Mapelli and S. Solinas and P. Lombardo and E. Cesana and D. Gandolfi and L. Congi"
}

@article{Berends2004,
title = "A detailed three-dimensional model of the cerebellar granular layer",
journal = "Neurocomputing",
volume = "58-60",
number = "",
pages = "587-592",
year = "2004",
author = "Michiel Berends and Reinoud Maex and Erik De Schutter",
keywords = "Cerebellum",
keywords = "Granule cell",
keywords = "Glomerulus",
keywords = "Golgi cell",
keywords = "Pattern separation"
}


@article{Bell2008,
author = {Bell, Curtis C. and Han, Victor and Sawtell, Nathaniel B.},
title = {Cerebellum-Like Structures and Their Implications for Cerebellar Function},
journal = {Annual Review of Neuroscience},
volume = {31},
number = {1},
pages = {1-24},
year = {2008}
}



@article{Holmes1917,
title = "The symptoms of acute cerebellar injuries due to gunshot injuries",
journal = "Brain",
volume = "40",
number = "4",
pages = "461-535",
year = "1917",
author = "Holmes,G"
}

@article{Harvey1988,
author = {Harvey, R. J. and Napper, R. M. A.},
title = {Quantitative study of granule and {P}urkinje cells in the cerebellar cortex of the rat},
journal = {The Journal of Comparative Neurology},
volume = {274},
number = {2},
publisher = {Alan R. Liss, Inc.},
issn = {1096-9861},
pages = {151--157},
keywords = {stereology, density, parallel fiber, Purkinje cell layer, granular layer},
year = {1988},
}

@article{Napper1988,
author = {Napper, R. M. A. and Harvey, R. J.},
title = {Number of parallel fiber synapses on an individual {P}urkinje cell in the cerebellum of the rat},
journal = {The Journal of Comparative Neurology},
volume = {274},
number = {2},
publisher = {Alan R. Liss, Inc.},
issn = {1096-9861},
pages = {168--177},
keywords = {stereology, molecular layer, dendritic spine, electron microscopic},
year = {1988},
}

@article{Kanichay2008,
author = {Kanichay, Roby T. and Silver, R. Angus}, 
title = {Synaptic and Cellular Properties of the Feedforward Inhibitory Circuit within the Input Layer of the Cerebellar Cortex}, 
volume = {28}, 
number = {36}, 
pages = {8955-8967}, 
year = {2008}, 
abstract ={Precise representation of the timing of sensory stimuli is essential for rapid motor coordination, a core function of the cerebellum. Feedforward inhibition has been implicated in precise temporal signaling in several regions of the brain, but little is known about this type of inhibitory circuit within the input layer of the cerebellar cortex. We investigated the synaptic properties of feedforward inhibition at near physiological temperatures (35°C) in rat cerebellar slices. We establish that the previously uncharacterized mossy fiber–Golgi cell–granule cell pathway can act as a functional feedforward inhibitory circuit. The synchronous activation of four mossy fibers, releasing a total of six quanta onto a Golgi cell, can reset spontaneous Golgi cell firing with high temporal precision (200 μs). However, only modest increases in Golgi cell firing rate were observed during trains of high-frequency mossy fiber stimulation. This decoupling of Golgi cell activity from mossy fiber firing rate was attributable to a strong afterhyperpolarization after each action potential, preventing mossy fiber–Golgi cell signaling for ∼50 ms. Feedforward excitation of Golgi cells induced a temporally precise inhibitory conductance in granule cells that curtailed the excitatory action of the mossy fiber EPSC. The synaptic and cellular properties of this feedforward circuit appear tuned to trigger a fast inhibitory conductance in granule cells at the onset of stimuli that produce intense bursts of activity in multiple mossy fibers, thereby conserving the temporal precision of the initial granule cell response.}, 
journal = {The Journal of Neuroscience} 
}

@ARTICLE{Apps2005,
author={Apps, R. and Garwicz, M.},
title={Anatomical and physiological foundations of cerebellar information processing},
journal={Nature Reviews Neuroscience},
year={2005},
volume={6},
number={4},
pages={297-311},
document_type={Review},
source={Scopus},
}

@article{Dino2000,
title = "Unipolar brush cell: a potential feedforward excitatory interneuron of the cerebellum",
journal = "Neuroscience",
volume = "98",
number = "4",
pages = "625-636",
year = "2000",
issn = "0306-4522",
author = "M. R. Dino and R. J. Schuerger and Y. -B. Liu and N. T. Slater and E. Mugnaini",
keywords = "cerebellar glomerulus",
keywords = "cerebellar granule cell",
keywords = "cerebellar mossy fibers",
keywords = "patch-clamp recording",
keywords = "Biocytin"
}

@article{Braitenberg1958,
author = {Braitenberg, Valentino and Atwood, Roger P.},
title = {Morphological observations on the cerebellar cortex},
journal = {The Journal of Comparative Neurology},
volume = {109},
number = {1},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
issn = {1096-9861},
pages = {1--33},
year = {1958},
}

@article{Ito1982,
author = {Ito, Masao and Sakurai, Masaki and Tongroach, Pavich}, 
title = {Climbing fibre induced depression of both mossy fibre responsiveness and glutamate sensitivity of cerebellar {P}urkinje cells}, 
volume = {324}, 
number = {1}, 
pages = {113-134}, 
year = {1982}, 
abstract ={1. In high decerebrate rabbits, cells were sampled extracellularly from the rostral flocculus. Purkinje cells were identified by their characteristic responses to stimulation of the contralateral inferior olive. Identification of basket cells was based on the absence of olivary responses and also on their location in the molecular layer adjacent to identified Purkinje cells. Mass field potentials in the flocculus were also studied.2. Single pulse stimulation of a vestibular nerve, either ipsilateral or contralateral, at a rate of 2/sec excited Purkinje cells with a latency of 3-6 msec. This early excitation represents activation through vestibular mossy fibres, granule cells and their axons (parallel fibres). Similar early excitation also occurred in putative basket cells.3. Conjunctive stimulation of a vestibular nerve at 20/sec and the inferior olive at 4/sec, for 25 sec per trial, effectively depressed the early excitation of Purkinje cells by that nerve, without an associated change in spontaneous discharge. The depression recovered in about ten minutes. This recovery was followed by the onset of a slow depression lasting for an hour.4. Conjunctive vestibular—olivary stimulation produced no such depression in the following responses: early excitation in Purkinje cells induced from the vestibular nerve not involved in the conjunctive stimulation; early excitation in putative basket cells from either vestibular nerve; inhibition or rebound facilitation in Purkinje cells following the early excitation; vestibular-evoked field potentials in the granular layer and white matter of the flocculus. These observations lead to the conclusion that the depression occurs specifically at parallel fibre—Purkinje cell synapses involved in conjunctive stimulation.5. Ionophoretic application of glutamate to Purkinje cells in conjunction with 4/sec olivary stimulation depressed the glutamate sensitivity of Purkinje cells; aspartate sensitivity was depressed to a much lesser degree. The depression diminished in about 10 min, but this recovery was succeeded by a slow depression lasting for an hour. The depression was seen only when glutamate sensitivity was relatively high, suggesting that the micro-electrode was impinging onto Purkinje cell dendrites. These observations suggest that subsynaptic chemosensitivity of Purkinje cells to the putative neurotransmitter of parallel fibres is involved in the depression observed after conjunctive stimulation of a vestibular nerve and the inferior olive.6. The present results are consistent with the Marr-Albus assumption concerning plasticity of cerebellar neuronal networks.},
journal = {The Journal of Physiology} 
}


@article{Wolpert1998,
title = "Internal models in the cerebellum",
journal = "Trends in Cognitive Sciences",
volume = "2",
number = "9",
pages = "338-347",
year = "1998",
issn = "1364-6613",
author = "Daniel M. Wolpert and R. Chris Miall and Mitsuo Kawato",
keywords = "cerebellum",
keywords = "internal model",
keywords = "forward model",
keywords = "inverse model",
keywords = "motor control"
}

@article{Hansel2001,
author = {Hansel, C. and Linden, D. J. and D'Angelo, E.},
title = {Beyond parallel fiber {LTD}: the diversity of synaptic and non-synaptic plasticity in the cerebellum.},
journal = {Nature Neuroscience},
volume = {4},
number = {5},
pages = {467-75},
abstract = {In recent years, it has become clear that motor learning, as revealed by associative eyelid conditioning and adaptation of the vestibulo-ocular reflex, contributes to the well-established cerebellar functions of sensorimotor integration and control. Long-term depression of the parallel fiber-Purkinje cell synapse (which is often called 'cerebellar LTD') is a cellular phenomenon that has been suggested to underlie these forms of learning. However, it is clear that parallel fiber LTD, by itself, cannot account for all the properties of cerebellar motor learning. Here we review recent electrophysiological experiments that have described a rich variety of use-dependent plasticity in cerebellum, including long-term potentiation (LTP) and LTD of excitatory and inhibitory synapses, and persistent modulation of intrinsic neuronal excitability. Finally, using associative eyelid conditioning as an example, we propose some ideas about how these cellular phenomena might function and interact to endow the cerebellar circuit with particular computational and mnemonic properties.},
year = {2001}
}

@article{DeZeeuw2008,
title = "Causes and Consequences of Oscillations in the Cerebellar Cortex",
journal = "Neuron",
volume = "58",
number = "5",
pages = "655-658",
year = "2008",
issn = "0896-6273",
author = "Chris I. De Zeeuw and Freek E. Hoebeek and Martijn Schonewille"
}

@article{Middleton2008,
title = "High-Frequency Network Oscillations in Cerebellar Cortex",
journal = "Neuron",
volume = "58",
number = "5",
pages = "763-774",
year = "2008",
issn = "0896-6273",
author = "Steven J. Middleton and Claudia Racca and Mark O. Cunningham and Roger D. Traub and Hannah Monyer and Thomas Knopfel and Ian S. Schofield and Alistair Jenkins and Miles A. Whittington",
keywords = "SYSNEURO",
keywords = "MOLNEURO",
keywords = "SIGNALING"
}

@article{Cohen1998,
author = {Cohen, Dana and Yarom, Yosef}, 
title = {Patches of synchronized activity in the cerebellar cortex evoked by mossy-fiber stimulation: Questioning the role of parallel fibers}, 
volume = {95}, 
number = {25}, 
pages = {15032-15036}, 
year = {1998}, 
abstract ={The discrepancy between the structural longitudinal organization of the parallel-fiber system in the cerebellar cortex and the functional mosaic-like organization of the cortex has provoked controversial theories about the flow of information in the cerebellum. We address this issue by characterizing the spatiotemporal organization of neuronal activity in the cerebellar cortex by using optical imaging of voltage-sensitive dyes in isolated guinea-pig cerebellum. Parallel-fiber stimulation evoked a narrow beam of activity, which propagated along the parallel fibers. Stimulation of the mossy fibers elicited a circular, nonpropagating patch of synchronized activity. These results strongly support the hypothesis that a beam of parallel fibers, activated by a focal group of granule cells, fails to activate the Purkinje cells along most of its length. It is thus the ascending axon of the granule cell, and not its parallel branches, that activates and defines the basic functional modules of the cerebellar cortex.}, 
journal = {Proceedings of the National Academy of Sciences} 
}



@article{Nordlie2009,
    author = {Nordlie, Eilen AND Gewaltig, Marc-Oliver AND Plesser, Hans Ekkehard},
    journal = {PLoS Computational Biology},
    publisher = {Public Library of Science},
    title = {Towards Reproducible Descriptions of Neuronal Network Models},
    year = {2009},
    month = {08},
    volume = {5},
    pages = {e1000456},
    abstract = {<title>Author Summary</title>
<p>Scientists make precise, testable statements about their observations and models of nature. Other scientists can then evaluate these statements and attempt to reproduce or extend them. Results that cannot be reproduced will be duly criticized to arrive at better interpretations of experimental results or better models. Over time, this discourse develops our joint scientific knowledge. A crucial condition for this process is that scientists can describe their own models in a manner that is precise and comprehensible to others. We analyze in this paper how well models of neuronal networks are described in the scientific literature and conclude that the wide variety of manners in which network models are described makes it difficult to communicate models successfully. We propose a <italic>good model description practice</italic> to improve the communication of neuronal network models.</p>
},
    number = {8}
} 

@article{Koene2009,
   author = {Koene, Randal and Tijms, Betty and van Hees, Peter and Postma, Frank and de Ridder, Alexander and Ramakers, Ger and van Pelt, Jaap and van Ooyen, Arjen},
   affiliation = {VU University Amsterdam Department of Integrative Neurophysiology, Center for Neurogenomics and Cognitive Research De Boelelaan 1085 1081 HV Amsterdam the Netherlands},
   title = {{NETMORPH}: A Framework for the Stochastic Generation of Large Scale Neuronal Networks With Realistic Neuron Morphologies},
   journal = {Neuroinformatics},
   publisher = {Humana Press Inc.},
   keyword = {Biomedical and Life Sciences},
   pages = {195-210},
   volume = {7},
   issue = {3},
   year = {2009}
}


@article{vanOoyen2011,
   author = {van Ooyen, A.},
   title = {Using theoretical models to analyse neural development},
   journal = {Nature Reviews Neuroscience},
   volume = {12},
   number = {6},
   pages = {311-26},
   abstract = {The development of the nervous system is an extremely complex and dynamic process. Through the continuous interplay of genetic information and changing intra- and extracellular environments, the nervous system constructs itself from precursor cells that divide and form neurons, which migrate, differentiate and establish synaptic connections. Our understanding of neural development can be greatly assisted by mathematical and computational modelling, because it allows us to bridge the gap between system-level dynamics and the lower level cellular and molecular processes. This Review shows the potential of theoretical models to examine many aspects of neural development.},
   keywords = {Animals
Brain
Cell Differentiation
Cell Movement
Cell Proliferation
Models, Neurological
Nerve Net
Neurons
Neurulation},
   year = {2011}
}



@article{Vogels2005,
author = {Vogels, Tim P. and Abbott, L. F.}, 
title = {Signal Propagation and Logic Gating in Networks of Integrate-and-Fire Neurons}, 
volume = {25}, 
number = {46}, 
pages = {10786-10795}, 
year = {2005}, 
abstract ={
         Transmission of signals within the brain is essential for cognitive function, but it is not clear how neural circuits support
         reliable and accurate signal propagation over a sufficiently large dynamic range. Two modes of propagation have been studied:
         synfire chains, in which synchronous activity travels through feedforward layers of a neuronal network, and the propagation
         of fluctuations in firing rate across these layers. In both cases, a sufficient amount of noise, which was added to previous
         models from an external source, had to be included to support stable propagation. Sparse, randomly connected networks of spiking
         model neurons can generate chaotic patterns of activity. We investigate whether this activity, which is a more realistic noise
         source, is sufficient to allow for signal transmission. We find that, for rate-coded signals but not for synfire chains, such
         networks support robust and accurate signal reproduction through up to six layers if appropriate adjustments are made in synaptic
         strengths. We investigate the factors affecting transmission and show that multiple signals can propagate simultaneously along
         different pathways. Using this feature, we show how different types of logic gates can arise within the architecture of the
         random network through the strengthening of specific synapses. 
      }, 
journal = {The Journal of Neuroscience} 
}


@article{KochSegev2000,
   author = {Koch, C. and Segev, I.},
   title = {The role of single neurons in information processing.},
   journal = {Nature Neuroscience},
   volume = {3 Suppl},
   pages = {1171-7},
   abstract = {Neurons carry out the many operations that extract meaningful information from sensory receptor arrays at the organism's periphery and translate these into action, imagery and memory. Within today's dominant computational paradigm, these operations, involving synapses, membrane ionic channels and changes in membrane potential, are thought of as steps in an algorithm or as computations. The role of neurons in these computations has evolved conceptually from that of a simple integrator of synaptic inputs until a threshold is reached and an output pulse is initiated, to a much more sophisticated processor with mixed analog-digital logic and highly adaptive synaptic elements.},
   keywords = {Action Potentials
Animals
Cell Membrane
Cell Size
Dendrites
Humans
Ion Channels
Models, Neurological
Neuronal Plasticity
Synapses},
   year = {2000}
}


@incollection{Dayan2006,
title = {Levels of Analysis in Neural Modeling},
author = {Dayan, Peter},
publisher = {John Wiley and Sons, Ltd},
isbn = {9780470018866},
keywords = {reductive models, computational models, quantitative models},
booktitle = {Encyclopedia of Cognitive Science},
year = {2006},
}


@article{Silver2010,
   author = {Silver, R. A.},
   title = {Neuronal arithmetic.},
   journal = {Nature Reviews Neuroscience},
   volume = {11},
   number = {7},
   pages = {474-89},
   abstract = {The vast computational power of the brain has traditionally been viewed as arising from the complex connectivity of neural networks, in which an individual neuron acts as a simple linear summation and thresholding device. However, recent studies show that individual neurons utilize a wealth of nonlinear mechanisms to transform synaptic input into output firing. These mechanisms can arise from synaptic plasticity, synaptic noise, and somatic and dendritic conductances. This tool kit of nonlinear mechanisms confers considerable computational power on both morphologically simple and more complex neurons, enabling them to perform a range of arithmetic operations on signals encoded ina variety of different ways.},
   keywords = {Animals
Dendrites
Humans
Mathematics
Nerve Net
Neurons
Synapses
Synaptic Transmission},
   year = {2010}
}



@article{London2005,
author = {London, Michael and H\"{a}usser, Michael},
title = {DENDRITIC COMPUTATION},
journal = {Annual Review of Neuroscience},
volume = {28},
number = {1},
pages = {503-532},
year = {2005},
}

@book{Koch1998,
    author = {Koch, Christof and Segev, Idan},
    keywords = {nafi},
    priority = {2},
    publisher = {MIT Press},
    title = {{Methods in Neuronal Modeling}},
    year = {1998}
}




@incollection{RallAgmonSnir1998,
   author = {Rall, W and Agmon-Snir, H},
   title = {Cable Theory for Dendritic Neurons},
   editor = {Koch, Christof and Segev, Idan},
    publisher = {MIT Press},
    booktitle = {{Methods in Neuronal Modeling}},
    year = {1998}
}

@incollection{SegevBurke1998,
   author = {Segev, Idan and Burke, Robert E},
   title = {Compartmental models of complex neurons},
   editor = {Koch, Christof and Segev, Idan},
    publisher = {MIT Press},
    booktitle = {{Methods in Neuronal Modeling}},
    year = {1998}
}

@article{Johnston2008,
title = "Active dendrites: colorful wings of the mysterious butterflies",
journal = "Trends in Neurosciences",
volume = "31",
number = "6",
pages = "309-316",
year = "2008",
note = "",
issn = "0166-2236",
author = "Daniel Johnston and Rishikesh Narayanan"
}


@article{Migliore2002,
   author = {Migliore, M. and Shepherd, G. M.},
   title = {Emerging rules for the distributions of active dendritic conductances.},
   journal = {Nature Reviews Neuroscience},
   volume = {3},
   number = {5},
   pages = {362-70},
   abstract = {A key goal in neuroscience is to explain how the operations of a neuron emerge from sets of active channels with specific dendritic distributions. If general principles can be identified for these distributions, dendritic channels should reflect the computational role of a given cell type within its functional neural circuit. Here, we discuss insights from experimental and computational data on the distribution of voltage-gated channels in dendrites, and attempt to derive rules for how their interactions implement different dendritic functions. We propose that this type of analysis will be important for understanding behavioural processes in terms of single-neuron properties, and that it constitutes a step towards a 'functional proteomics' of nerve cells, which will be essential for defining neuronal phenotypes.},
   keywords = {Animals
Dendrites
Humans
Ion Channels
Neural Conduction
Neurons
Synapses},
   year = {2002}
}

@article{Marder2011,
   author = {Marder, E. and Taylor, A. L.},
   title = {Multiple models to capture the variability in biological neurons and networks.},
   journal = {Nature Neuroscience},
   volume = {14},
   number = {2},
   pages = {133-8},
   abstract = {How tightly tuned are the synaptic and intrinsic properties that give rise to neuron and circuit function? Experimental work shows that these properties vary considerably across identified neurons in different animals. Given this variability in experimental data, this review describes some of the complications of building computational models to aid in understanding how system dynamics arise from the interaction of system components. We argue that instead of trying to build a single model that captures the generic behavior of a neuron or circuit, it is beneficial to construct a population of models that captures the behavior of the population that provided the experimental data. Studying a population of models with different underlying structure and similar behaviors provides opportunities to discover unsuspected compensatory mechanisms that contribute to neuron and network function.},
   keywords = {Animals
Electrophysiology
Membrane Potentials
Models, Neurological
Nerve Net
Neural Conduction
Neurons},
   year = {2011}
}

@article{Segev2000,
author = {Segev, Idan and London, Michael}, 
title = {Untangling Dendrites with Quantitative Models}, 
volume = {290}, 
number = {5492}, 
pages = {744-750}, 
year = {2000}, 
abstract ={Our understanding of the function of dendrites has been greatly enriched by an inspiring dialogue between theory and experiments. Rather than functionally ignoring dendrites, representing neurons as single summing points, we have realized that dendrites are electrically and chemically distributed nonlinear units and that this has important consequences for interpreting experimental data and for the role of neurons in information processing. Here, we examine the route to unraveling some of the enigmas of dendrites and highlight the main insights that have been gained. Future directions are discussed that will enable theory and models to keep shedding light on dendrites, where the most fundamental input-output adaptive processes take place.}, 
journal = {Science} 
}




@incollection{DestexheHuguenard,
   author = {Alain Destexhe and John R. Huguenard},
   title = {Which formalism to use for modeling voltage-dependent conductances?},
   editor = {Erik De Schutter},
    publisher = {CRC Press, Boca Raton FL},
    booktitle = {{Computational Neuroscience: Realistic Modeling for Experimentalists}},
    year = {2000}
}

@article{Fink2009,
author = {Fink, Martin and Noble, Denis}, 
title = {Markov models for ion channels: versatility versus identifiability and speed}, 
volume = {367}, 
number = {1896}, 
pages = {2161-2179}, 
year = {2009}, 
abstract ={Markov models (MMs) represent a generalization of Hodgkin–Huxley models. They provide a versatile structure for modelling single channel data, gating currents, state-dependent drug interaction data, exchanger and pump dynamics, etc. This paper uses examples from cardiac electrophysiology to discuss aspects related to parameter estimation. (i) Parameter unidentifiability (found in 9 out of 13 of the considered models) results in an inability to determine the correct layout of a model, contradicting the idea that model structure and parameters provide insights into underlying molecular processes. (ii) The information content of experimental voltage step clamp data is discussed, and a short but sufficient protocol for parameter estimation is presented. (iii) MMs have been associated with high computational cost (owing to their large number of state variables), presenting an obstacle for multicellular whole organ simulations as well as parameter estimation. It is shown that the stiffness of models increases computation time more than the number of states. (iv) Algorithms and software programs are provided for steady-state analysis, analytical solutions for voltage steps and numerical derivation of parameter identifiability. The results provide a new standard for ion channel modelling to further the automation of model development, the validation process and the predictive power of these models.}, 
journal = {Philosophical Transactions of the Royal Society A: Mathematical,
				Physical and Engineering Sciences} 
}

@article{Rall1959,
title = "Branching dendritic trees and motoneuron membrane resistivity",
journal = "Experimental Neurology",
volume = "1",
number = "5",
pages = "491-527",
year = "1959",
note = "",
issn = "0014-4886",
author = "Wilfrid Rall"
}

@article{Single1998,
author = {Single, Sandra and Borst, Alexander}, 
title = {Dendritic Integration and Its Role in Computing Image Velocity}, 
volume = {281}, 
number = {5384}, 
pages = {1848-1850}, 
year = {1998}, 
abstract ={The mechanisms underlying visual motion detection can be studied simultaneously in different cell compartments in vivo by using calcium as a reporter of the spatiotemporal activity distribution in single motion-sensitive cells of the fly. As predicted by the Reichardt model, local dendritic calcium signals are found to indicate the direction and velocity of pattern motion but are corrupted by spatial pattern properties. The latter are canceled out by spatial integration, thus leading to a purely directional selective output signal in the axon. These findings attribute a specific computational task to the dendrites of visual interneurons and imply a functional interpretation of dendritic morphology.}, 
journal = {Science} 
}

@article{AgmonSnir1998,
   author = {Agmon-Snir, H. and Carr, C. E. and Rinzel, J.},
   title = {The role of dendrites in auditory coincidence detection.},
   journal = {Nature},
   volume = {393},
   number = {6682},
   pages = {268-72},
   abstract = {Coincidence-detector neurons in the auditory brainstem of mammals and birds use interaural time differences to localize sounds. Each neuron receives many narrow-band inputs from both ears and compares the time of arrival of the inputs with an accuracy of 10-100 micros. Neurons that receive low-frequency auditory inputs (up to about 2 kHz) have bipolar dendrites, and each dendrite receives inputs from only one ear. Using a simple model that mimics the essence of the known electrophysiology and geometry of these cells, we show here that dendrites improve the coincidence-detection properties of the cells. The biophysical mechanism for this improvement is based on the nonlinear summation of excitatory inputs in each of the dendrites and the use of each dendrite as a current sink for inputs to the other dendrite. This is a rare case in which the contribution of dendrites to the known computation of a neuron may be understood. Our results show that, in these neurons, the cell morphology and the spatial distribution of the inputs enrich the computational power of these neurons beyond that expected from 'point neurons' (model neurons lacking dendrites).},
   keywords = {Action Potentials
Animals
Auditory Pathways
Auditory Perception
Brain Stem
Chickens
Dendrites
Hearing
Models, Neurological},
   year = {1998}
}

@article{Hines1984,
title = "Efficient computation of branched nerve equations",
journal = "International Journal of Bio-Medical Computing",
volume = "15",
number = "1",
pages = "69-76",
year = "1984",
issn = "0020-7101",
author = "Michael Hines"
}

@article{Prinz2004,
   author = {Prinz, A. A. and Bucher, D. and Marder, E.},
   title = {Similar network activity from disparate circuit parameters.},
   journal = {Nature Neuroscience},
   volume = {7},
   number = {12},
   pages = {1345-52},
   abstract = {It is often assumed that cellular and synaptic properties need to be regulated to specific values to allow a neuronal network to function properly. To determine how tightly neuronal properties and synaptic strengths need to be tuned to produce a given network output, we simulated more than 20 million versions of a three-cell model of the pyloric network of the crustacean stomatogastric ganglion using different combinations of synapse strengths and neuron properties. We found that virtually indistinguishable network activity can arise from widely disparate sets of underlying mechanisms, suggesting that there could be considerable animal-to-animal variability in many of the parameters that control network activity, and that many different combinations of synaptic strengths and intrinsic membrane properties can be consistent with appropriate network performance.},
   keywords = {Action Potentials
Animals
Crustacea
Nerve Net
Neurons
Synapses},
   year = {2004}
}

@article{WattsStrogatz,
   author = {Watts, D. J. and Strogatz, S. H.},
   title = {Collective dynamics of ``small-world'' networks.},
   journal = {Nature},
   volume = {393},
   number = {6684},
   pages = {440-2},
   abstract = {Networks of coupled dynamical systems have been used to model biological oscillators, Josephson junction arrays, excitable media, neural networks, spatial games, genetic control networks and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them 'small-world' networks, by analogy with the small-world phenomenon (popularly known as six degrees of separation. The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.},
   keywords = {Animals
Caenorhabditis elegans
Communicable Diseases
Games, Experimental
Models, Biological
Models, Neurological
Models, Theoretical
Nerve Net},
   year = {1998}
}


@article{Grillner2005,
title = "Microcircuits in action: from {CPG}s to neocortex",
journal = "Trends in Neurosciences",
volume = "28",
number = "10",
pages = "525-533",
year = "2005",
note = "",
issn = "0166-2236",
author = "Sten Grillner and Henry Markram and Erik De Schutter and Gilad Silberberg and Fiona E.N. LeBeau"
}



@article{Medina2000,
author = {Medina, Javier F. and Garcia, Keith S. and Nores, William L. and Taylor, Nichole M. and Mauk, Michael D.}, 
title = {Timing Mechanisms in the Cerebellum: Testing Predictions of a Large-Scale Computer Simulation}, 
volume = {20}, 
number = {14}, 
pages = {5516-5525}, 
year = {2000}, 
abstract ={We used large-scale computer simulations of eyelid conditioning to investigate how the cerebellum generates and makes use of temporal information. In the simulations the adaptive timing displayed by conditioned responses is mediated by two factors: (1) different sets of granule cells are active at different times during the conditioned stimulus (CS), and (2) responding is not only amplified at reinforced times but also suppressed at unreinforced times during the CS. These factors predict an unusual pattern of responding after partial removal of the cerebellar cortex that was confirmed using small, electrolytic lesions of cerebellar cortex. These results are consistent with timing mechanisms in the cerebellum that are similar to Pavlov's “inhibition of delay” hypothesis.}, 
journal = {The Journal of Neuroscience} 
}

@article{OHYAMA2002,
author = {Ohyama, Tatsuya and Medina, Javier F. and Nores, William L. and Mauk, Michael D.},
title = {Trying to Understand the Cerebellum Well Enough to Build One},
journal = {Annals of the New York Academy of Sciences},
volume = {978},
number = {1},
publisher = {Blackwell Publishing Ltd},
issn = {1749-6632},
pages = {425-438},
keywords = {cerebellum, extinction, eyelid conditioning, inferior olive, motor learning, Pavlov, rabbit, simulation},
year = {2002},
}

@article{Steuber2011,
   author = {Steuber, Volker and Schultheiss, Nathan and Silver, R. and De Schutter, Erik and Jaeger, Dieter},
   affiliation = {Science and Technology Research Institute, University of Hertfordshire, Hatfield Herts, AL10 9AB UK},
   title = {Determinants of synaptic integration and heterogeneity in rebound firing explored with data-driven models of deep cerebellar nucleus cells},
   journal = {Journal of Computational Neuroscience},
   publisher = {Springer Netherlands},
   issn = {0929-5313},
   keyword = {Computer Science},
   pages = {633-658},
   volume = {30},
   issue = {3},
   year = {2011}
}


@article{Molineux2005,
author = {Molineux, Michael L. and Fernandez, Fernando R. and Mehaffey, W. Hamish and Turner, Ray W.}, 
title = {A-Type and {T}-Type Currents Interact to Produce a Novel Spike Latency-Voltage Relationship in Cerebellar Stellate Cells}, 
volume = {25}, 
number = {47}, 
pages = {10863-10873}, 
year = {2005}, 
abstract ={
         The modification of first-spike latencies by low-threshold and inactivating K+ currents (IA) have important implications in neuronal coding and synaptic integration. To date, cells in which first-spike latency characteristics
         have been analyzed have shown that increased hyperpolarization results in longer first-spike latencies, producing a monotonic
         relationship between first-spike latency and membrane voltage. Previous work has established that cerebellar stellate cells
         express members of the Kv4 potassium channel subfamily, which underlie IA in many central neurons. Spike timing in stellate cells could be particularly important to cerebellar output, because the
         discharge of even single spikes can significantly delay spike discharge in postsynaptic Purkinje cells. In the present work,
         we studied the first-spike latency characteristics of stellate cells. We show that first-spike latency is nonmonotonic, such
         that intermediate levels of prehyperpolarization produce the longest spike latencies, whereas greater hyperpolarization or
         depolarization reduces spike latency. Moreover, the range of first-spike latency values can be substantial in spanning 20-128
         ms with preceding membrane shifts of <10 mV. Using patch clamp and modeling, we illustrate that spike latency characteristics
         are the product of an interplay between IA and low-threshold calcium current (IT) that requires a steady-state difference in the inactivation parameters of the currents. Furthermore, we show that the unique
         first-spike latency characteristics of stellate cells have important implications for the integration of coincident IPSPs
         and EPSPs, such that inhibition can shift first-spike latency to differentially modulate the probability of firing. 
      }, 
journal = {The Journal of Neuroscience} 
}

@article{Nieus2006,
author = {Nieus, Thierry and Sola, Elisabetta and Mapelli, Jonathan and Saftenku, Elena and Rossi, Paola and D'Angelo, Egidio}, 
title = {{LTP} Regulates Burst Initiation and Frequency at Mossy Fiber-Granule Cell Synapses of Rat Cerebellum: Experimental Observations and Theoretical Predictions}, 
volume = {95}, 
number = {2}, 
pages = {686-699}, 
year = {2006}, 
abstract ={
         Long-term potentiation (LTP) is a synaptic change supposed to provide the cellular basis for learning and memory in brain
         neuronal circuits. Although specific LTP expression mechanisms could be critical to determine the dynamics of repetitive neurotransmission,
         this important issue remained largely unexplored. In this paper, we have performed whole cell patch-clamp recordings of mossy
         fiber–granule cell LTP in acute rat cerebellar slices and studied its computational implications with a mathematical model.
         During LTP, stimulation with short impulse trains at 100 Hz revealed earlier initiation of granule cell spike bursts and a
         smaller nonsignificant spike frequency increase. In voltage-clamp recordings, short AMPA excitatory postsynaptic current (EPSC)
         trains showed short-term facilitation and depression and a sustained component probably generated by spillover. During LTP,
         facilitation disappeared, depression accelerated, and the sustained current increased. The N-methyl-D-aspartate (NMDA) current also increased. In agreement with a presynaptic expression caused by increased release probability,
         similar changes were observed by raising extracellular [Ca2+]. A mathematical model of mossy fiber–granule cell neurotransmission showed that increasing release probability efficiently
         modulated the first-spike delay. Glutamate spillover, by causing tonic NMDA and AMPA receptor activation, accelerated excitatory
         postsynaptic potential (EPSP) temporal summation and maintained a sustained spike discharge. The effect of increasing neurotransmitter
         release could not be replicated by increasing receptor conductance, which, like postsynaptic manipulations enhancing intrinsic
         excitability, proved very effective in raising granule cell output frequency. Independent regulation of spike burst initiation
         and frequency during LTP may provide mechanisms for temporal recoding and gain control of afferent signals at the input stage
         of cerebellar cortex. 
      }, 
journal = {Journal of Neurophysiology} 
}


@article{Lubke2003,
author = {L\"{u}bke, Joachim and Roth, Arnd and Feldmeyer, Dirk and Sakmann, Bert}, 
title = {Morphometric Analysis of the Columnar Innervation Domain of Neurons Connecting Layer 4 and Layer 2/3 of Juvenile Rat Barrel Cortex}, 
volume = {13}, 
number = {10}, 
pages = {1051-1063}, 
year = {2003}, 
abstract ={We have investigated the dendritic and axonal morphology of connected pairs of L4 spiny neurons and L2/3 pyramidal cells in rat barrel cortex. The ‘projection’ field of the axons of L4 spiny neurons in layers 2/3, 4 and 5 has a width of 400–500 μm thereby defining an anatomical barrel-column. In layer 2/3, the averaged axonal ‘projection’ field of L4 spiny neurons together with the dendritic ‘receptive’ field of the connected L2/3 pyramidal cells form a mostly column-restricted anatomical L4-to-L2/3 ‘innervation domain’ that extends 300–400 μm and includes mostly basal dendrites. In the L4-to-L2/3 innervation domain a single L4 spiny neuron contacts ~300–400 pyramidal cells while in the L4-to-L4 innervation domain it contacts ~200 other L4 spiny neurons. Similarly ~300–400 L4 spiny neurons converge onto a single pyramidal cell and ~200 L4 spiny neurons innervate another L4 spiny neuron. The L2/3 pyramidal cell axon has a vertical projection field spanning all cortical layers, and a long-range horizontal field in layers 2/3 (width 1100–1200 μm) and 5 (700–800 μm) projecting across column borders. The results suggest that the flow of excitation within a barrel-column is determined by the largely columnar confinement of the L4-to-L4 and L4-to-L2/3 innervation domains. A whisker deflection activates ~140 L4 spiny neurons that will generate EPSPs in most barrel-related L2/3 pyramidal cells of a principal whisker column. The translaminar synaptic transmission to layer 2/3 and the axonal projection fields of L2/3 pyramidal cells are the major determinants of the dynamic, multi-columnar map in which a single whisker deflection is represented in the cortex.}, 
journal = {Cerebral Cortex} 
}




@article{Song2005,
    author = {Song, Sen AND Sj\"{o}str\"{o}m, Per Jesper AND Reigl, Markus AND Nelson, Sacha AND Chklovskii, Dmitri B},
    journal = {PLoS Biology},
    publisher = {Public Library of Science},
    title = {Highly Nonrandom Features of Synaptic Connectivity in Local Cortical Circuits},
    year = {2005},
    month = {03},
    volume = {3},
    pages = {e68},
    abstract = {
        <p>A dataset of hundreds of recordings in which four neurons were simultaneously monitored reveals clustered connectivity patterns among cortical neurons.</p>
      },
    number = {3}
}        


@article{Sporns2004,
    author = {Sporns, Olaf AND Kotter, Rolf},
    journal = {PLoS Biology},
    publisher = {Public Library of Science},
    title = {Motifs in Brain Networks},
    year = {2004},
    month = {10},
    volume = {2},
    pages = {e369},
    abstract = {
        <p>Analysis of characteristic patterns of connectivity in neuroanatomical datasets suggests that nervous systems evolved to maximize functional repertoires and support highly efficient integration of information.</p>
      },
    number = {11}
}        

@article{Yoshimura2005,
   author = {Yoshimura, Y. and Callaway, E. M.},
   title = {Fine-scale specificity of cortical networks depends on inhibitory cell type and connectivity.},
   journal = {Nature Neuroscience},
   volume = {8},
   number = {11},
   pages = {1552-9},
   abstract = {Excitatory cortical neurons form fine-scale networks of precisely interconnected neurons. Here we tested whether inhibitory cortical neurons in rat visual cortex might also be connected with fine-scale specificity. Using paired intracellular recordings and cross-correlation analyses of photostimulation-evoked synaptic currents, we found that fast-spiking interneurons preferentially connected to neighboring pyramids that provided them with reciprocal excitation. Furthermore, they shared common fine-scale excitatory input with neighboring pyramidal neurons only when the two cells were reciprocally connected, and not when there was no connection or a one-way, inhibitory-to-excitatory connection. Adapting inhibitory neurons shared little or no common input with neighboring pyramids, regardless of their direct connectivity. We conclude that inhibitory connections and also excitatory connections to inhibitory neurons can both be precise on a fine scale. Furthermore, fine-scale specificity depends on the type of inhibitory neuron and on direct connectivity between neighboring pyramidal-inhibitory neuron pairs.},
   keywords = {Action Potentials
Animals
Animals, Newborn
Electric Stimulation
Excitatory Postsynaptic Potentials
Interneurons
Nerve Net
Neural Inhibition
Neurons
Patch-Clamp Techniques
Photic Stimulation
Rats
Rats, Long-Evans
Statistics as Topic
Statistics, Nonparametric
Visual Cortex},
   year = {2005}
}

@article{Chemla2010,
title = "A biophysical cortical column model to study the multi-component origin of the {VSDI} signal",
journal = "NeuroImage",
volume = "53",
number = "2",
pages = "420-438",
year = "2010",
note = "",
issn = "1053-8119",
author = "S. Chemla and F. Chavane",
keywords = "Voltage-sensitive dye imaging (VSDI)",
keywords = "Biophysical model",
keywords = "Cortical column",
keywords = "Contrast response function (CRF)",
keywords = "NEURON simulations"
}

@Article{Hanson2010,
AUTHOR = {Hanson, Jesse and Madison, Daniel},
TITLE = {Imbalanced pattern completion vs. separation in cognitive disease: network simulations of synaptic pathologies predict a personalized therapeutics strategy},
JOURNAL = {BMC Neuroscience},
VOLUME = {11},
YEAR = {2010},
NUMBER = {1},
PAGES = {96},
PubMedID = {20704756},
ISSN = {1471-2202},
ABSTRACT = {BACKGROUND:Diverse Mouse genetic models of neurodevelopmental, neuropsychiatric, and neurodegenerative causes of impaired cognition exhibit at least four convergent points of synaptic malfunction: 1) Strength of long-term potentiation (LTP), 2) Strength of long-term depression (LTD), 3) Relative inhibition levels (Inhibition), and 4) Excitatory connectivity levels (Connectivity).RESULTS:To test the hypothesis that pathological increases or decreases in these synaptic properties could underlie imbalances at the level of basic neural network function, we explored each type of malfunction in a simulation of autoassociative memory. These network simulations revealed that one impact of impairments or excesses in each of these synaptic properties is to shift the trade-off between pattern separation and pattern completion performance during memory storage and recall. Each type of synaptic pathology either pushed the network balance towards intolerable error in pattern separation or intolerable error in pattern completion. Imbalances caused by pathological impairments or excesses in LTP, LTD, inhibition, or connectivity, could all be exacerbated, or rescued, by the simultaneous modulation of any of the other three synaptic properties.CONCLUSIONS:Because appropriate modulation of any of the synaptic properties could help re-balance network function, regardless of the origins of the imbalance, we propose a new strategy of personalized cognitive therapeutics guided by assay of pattern completion vs. pattern separation function. Simulated examples and testable predictions of this theorized approach to cognitive therapeutics are presented.},
}

@article{Helmstaedter2007,
title = "Reconstruction of an average cortical column in silico",
journal = "Brain Research Reviews",
volume = "55",
number = "2",
pages = "193-203",
year = "2007",
author = "M. Helmstaedter and C.P.J. de Kock and D. Feldmeyer and R.M. Bruno and B. Sakmann",
keywords = "Local circuits",
keywords = "Barrel cortex",
keywords = "Anatomical reconstruction",
keywords = "Behaviour",
keywords = "Decision making"
}

@ARTICLE{OConnor2009,
author={O'Connor, D.H. and Huber, D. and Svoboda, K. },
title={Reverse engineering the mouse brain},
journal={Nature},
year={2009},
volume={461},
number={7266},
pages={923-929},
affiliation={Janelia Farm Research Campus, Howard Hughes Medical Institute, 19700 Helix Drive, Ashburn, VI 20147, United States},
abstract={Behaviour is governed by activity in highly structured neural circuits. Genetically targeted sensors and switches facilitate measurement and manipulation of activity in vivo, linking activity in defined nodes of neural circuits to behaviour. Because of access to specific cell types, these molecular tools will have the largest impact in genetic model systems such as the mouse. Emerging assays of mouse behaviour are beginning to rival those of behaving monkeys in terms of stimulus and behavioural control. We predict that the confluence of new behavioural and molecular tools in the mouse will reveal the logic of complex mammalian circuits. © 2009 Macmillan Publishers Limited. All rights reserved.},
document_type={Review},
source={Scopus},
}

@article{StuartSakmann,
   author = {Stuart, G. J. and Sakmann, B.},
   title = {Active propagation of somatic action potentials into neocortical pyramidal cell dendrites.},
   journal = {Nature},
   volume = {367},
   number = {6458},
   pages = {69-72},
   abstract = {The dendrites of neurons in the mammalian central nervous system have been considered as electrically passive structures which funnel synaptic potentials to the soma and axon initial segment, the site of action potential initiation. More recent studies, however, have shown that the dendrites of many neurons are not passive, but contain active conductances. The role of these dendritic voltage-activated channels in the initiation of action potentials in neurons is largely unknown. To assess this directly, patch-clamp recordings were made from the dendrites of neocortical pyramidal cells in brain slices. Voltage-activated sodium currents were observed in dendritic outside-out patches, while action potentials could be evoked by depolarizing current pulses or by synaptic stimulation during dendritic whole-cell recordings. To determine the site of initiation of these action potentials, simultaneous whole-cell recordings were made from the soma and the apical dendrite or axon of the same cell. These experiments showed that action potentials are initiated first in the axon and then actively propagate back into the dendritic tree.},
   keywords = {Action Potentials
Animals
Axons
Dendrites
Lidocaine
Pyramidal Cells
Rats
Rats, Wistar
Sodium Channel Blockers
Sodium Channels},
   year = {1994}
}








